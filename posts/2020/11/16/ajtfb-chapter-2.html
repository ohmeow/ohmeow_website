<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>A Journey Through Fastbook (AJTFB) - Chapter 2: Doing Deep Learning | ohmeow</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="A Journey Through Fastbook (AJTFB) - Chapter 2: Doing Deep Learning" />
<meta name="author" content="Wayde Gilliam" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The second in a weekly-ish series where I revisit the fast.ai book, “Deep Learning for Coders with fastai &amp; PyTorch”, and provide commentary on the bits that jumped out to me chapter by chapter. So without further adieu, let’s go!" />
<meta property="og:description" content="The second in a weekly-ish series where I revisit the fast.ai book, “Deep Learning for Coders with fastai &amp; PyTorch”, and provide commentary on the bits that jumped out to me chapter by chapter. So without further adieu, let’s go!" />
<link rel="canonical" href="https://ohmeow.com/posts/2020/11/16/ajtfb-chapter-2.html" />
<meta property="og:url" content="https://ohmeow.com/posts/2020/11/16/ajtfb-chapter-2.html" />
<meta property="og:site_name" content="ohmeow" />
<meta property="og:image" content="https://ohmeow.com/images/articles/fastbook.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-16T00:00:00-06:00" />
<script type="application/ld+json">
{"dateModified":"2020-11-16T00:00:00-06:00","datePublished":"2020-11-16T00:00:00-06:00","url":"https://ohmeow.com/posts/2020/11/16/ajtfb-chapter-2.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://ohmeow.com/posts/2020/11/16/ajtfb-chapter-2.html"},"headline":"A Journey Through Fastbook (AJTFB) - Chapter 2: Doing Deep Learning","image":"https://ohmeow.com/images/articles/fastbook.jpg","author":{"@type":"Person","name":"Wayde Gilliam"},"description":"The second in a weekly-ish series where I revisit the fast.ai book, “Deep Learning for Coders with fastai &amp; PyTorch”, and provide commentary on the bits that jumped out to me chapter by chapter. So without further adieu, let’s go!","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ohmeow.com/feed.xml" title="ohmeow" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-163296836-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-163296836-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

    <div class="wrapper"><a class="site-title" rel="author" href="/"><img style="height: 60px;" src="/images/ohmeow_logo.png" alt="ohmeow.com"></a><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger" />
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
              </svg>
            </span>
          </label>
  
          <div class="trigger"><a class="page-link" href="/about/"><span class="top-menu-text">About Me</span></a><a class="page-link" href="/guides/"><span class="top-menu-text">Guides</span></a><a class="page-link" href="/search/"><span class="top-menu-text">Search</span></a><a class="page-link" href="/categories/"><span class="top-menu-text">Tags</span></a></div>
        </nav></div>
  </header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">A Journey Through Fastbook (AJTFB) - Chapter 2: Doing Deep Learning</h1><p class="page-description">The second in a weekly-ish series where I revisit the fast.ai book, <a href='https://github.com/fastai/fastbook'>"Deep Learning for Coders with fastai & PyTorch"</a>, and provide commentary on the bits that jumped out to me chapter by chapter.  So without further adieu, let's go!</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-11-16T00:00:00-06:00" itemprop="datePublished">
        Nov 16, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Wayde Gilliam</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      17 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#fastai">fastai</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#fastbook">fastbook</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/ohmeow/ohmeow_website/tree/master/_notebooks/2020-11-16-ajtfb-chapter-2.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/ohmeow/ohmeow_website/blob/master/_notebooks/2020-11-16-ajtfb-chapter-2.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Starting-Your-Project">Starting Your Project </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Things-to-think-about-when-deciding-on-project-feasibility">Things to think about when deciding on project feasibility </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#The-Drivetrain-Approach">The Drivetrain Approach </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Four-Steps">Four Steps </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Step-1:-Define-your-objective(s)">Step 1: Define your objective(s) </a></li>
<li class="toc-entry toc-h4"><a href="#Step-2:-What-actions-can-you-take-to-achieve-those-objective(s)?">Step 2: What actions can you take to achieve those objective(s)? </a></li>
<li class="toc-entry toc-h4"><a href="#Step-3:-What-data-is-needed-to-take-those-actions?">Step 3: What data is needed to take those actions? </a></li>
<li class="toc-entry toc-h4"><a href="#Step-4:-Build-models">Step 4: Build models </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#How-to-Avoid-Disaster">How to Avoid Disaster </a></li>
<li class="toc-entry toc-h2"><a href="#Getting-help">Getting help </a></li>
<li class="toc-entry toc-h2"><a href="#Getting-and-cleaning-your-images">Getting and cleaning your images </a></li>
<li class="toc-entry toc-h2"><a href="#DataBlock-API-Basics">DataBlock API Basics </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Defining-your-"blueprint"-using-the-DataBlock-API">Defining your &quot;blueprint&quot; using the DataBlock API </a></li>
<li class="toc-entry toc-h3"><a href="#Using-your-"blueprint"-to-build-your-DataLoaders">Using your &quot;blueprint&quot; to build your DataLoaders </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Transforms">Transforms </a>
<ul>
<li class="toc-entry toc-h3"><a href="#What-is-a-"Transform"?">What is a &quot;Transform&quot;? </a></li>
<li class="toc-entry toc-h3"><a href="#What-kinds-of-transforms-are-there?">What kinds of transforms are there? </a></li>
<li class="toc-entry toc-h3"><a href="#When-should-I-use-an-item-transform?">When should I use an item transform? </a></li>
<li class="toc-entry toc-h3"><a href="#When-should-I-use-a-batch-transform?">When should I use a batch transform? </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Data-augmentation">Data augmentation </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Tips-&-Tricks">Tips &amp; Tricks </a>
<ul>
<li class="toc-entry toc-h4"><a href="#1.-Changing-your-transforms-without-having-to-redefine-your-DataBlock-from-scratch">1. Changing your transforms without having to redefine your DataBlock from scratch </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#How-to-train-an-image-classification-model-with-the-high-level-API">How to train an image classification model with the high-level API </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Step-1:-Get-your-data">Step 1: Get your data </a></li>
<li class="toc-entry toc-h3"><a href="#Step-2:-Build-your-DataBlock">Step 2: Build your DataBlock </a></li>
<li class="toc-entry toc-h3"><a href="#Step-3:-Train-your-model">Step 3: Train your model </a></li>
<li class="toc-entry toc-h3"><a href="#Step-4:-Inference">Step 4: Inference </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Inference">Inference </a>
<ul>
<li class="toc-entry toc-h3"><a href="#export()-and-predict()">export() and predict() </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Resources">Resources </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-11-16-ajtfb-chapter-2.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">PIL</span>

<span class="kn">from</span> <span class="nn">fastai.data.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Other posts in this series:<br>
<a href="https://ohmeow.com/posts/2020/11/06/ajtfb-chapter-1.html">A Journey Through Fastbook (AJTFB) - Chapter 1</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Starting-Your-Project">
<a class="anchor" href="#Starting-Your-Project" aria-hidden="true"><span class="octicon octicon-link"></span></a>Starting Your Project<a class="anchor-link" href="#Starting-Your-Project"> </a>
</h2>
<h3 id="Things-to-think-about-when-deciding-on-project-feasibility">
<a class="anchor" href="#Things-to-think-about-when-deciding-on-project-feasibility" aria-hidden="true"><span class="octicon octicon-link"></span></a>Things to think about when deciding on project feasibility<a class="anchor-link" href="#Things-to-think-about-when-deciding-on-project-feasibility"> </a>
</h3>
<p>"When selecting a project, the most important consideration is data availability." If you don't have enough quality data ... good luck :)
</p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Consider that <strong>data augmentation</strong> can alleviate both the need for more manual labelling and also protect you from problems with <em>out-of-domain</em> data (e.g. when unexpected image types arise in the data when the model is being used in production) by synthetically creating more data likely to be seen that may not be in your dataset as is.
</div>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>"... iterate from end to end in your project; don’t spend months fine-tuning your model, or polishing the perfect GUI, or labeling the perfect dataset"
</div>
<p>This is good advice for <em>any</em> software project ...<strong><em>fail early and fail often</em></strong>. If you don't, you're likely to only uncover critical problems much later than you would have before, and even worse, you're likely to not produce anything at all! In the world of deep learning there are a number of tools, that while helpful, can really get you so bogged down that you never deploy something usable (e.g., experiment tracking tools, hyperparameter optimization libraries, etc...).</p>
<p>Also, remember that getting something in production is a different task from winning a kaggle competition, where the later may require use of some of those aforementioned tools and the ensembling of dozens of models. <strong><em>For production, something better than human is often good enough to get out there and through refactoring, improve.</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="The-Drivetrain-Approach">
<a class="anchor" href="#The-Drivetrain-Approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Drivetrain Approach<a class="anchor-link" href="#The-Drivetrain-Approach"> </a>
</h2>
<p><img src="https://raw.githubusercontent.com/ohmeow/ohmeow_website/master/images/articles/drivetrain-approach.png" alt=""></p>
<h3 id="Four-Steps">
<a class="anchor" href="#Four-Steps" aria-hidden="true"><span class="octicon octicon-link"></span></a>Four Steps<a class="anchor-link" href="#Four-Steps"> </a>
</h3>
<h4 id="Step-1:-Define-your-objective(s)">
<a class="anchor" href="#Step-1:-Define-your-objective(s)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 1: Define your objective(s)<a class="anchor-link" href="#Step-1:-Define-your-objective(s)"> </a>
</h4>
<p>It's amazing how in my 20+ years as a developer, how rare it is that a customer is able to clearly define what they want! In my experience, more than not, it is the developers that end up defining the goals. Not having a clear objective is likely to waste time, energy, and money to produce something that won't even see the light of day.  <strong><em>You can't gauge the completion or quality of any software project without clear objective(s).</em></strong></p>
<p>Ex.1: Show most relevant search results.<br>
Ex.2: Drive additional sales by recommending to customers items to purchase they otherwise wouldn't</p>
<h4 id="Step-2:-What-actions-can-you-take-to-achieve-those-objective(s)?">
<a class="anchor" href="#Step-2:-What-actions-can-you-take-to-achieve-those-objective(s)?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 2: What actions can you take to achieve those objective(s)?<a class="anchor-link" href="#Step-2:-What-actions-can-you-take-to-achieve-those-objective(s)?"> </a>
</h4>
<p>What things can make your goals a reality. Pretty simple.</p>
<p>Ex.1: Ranking the search results will help show the most relevants ones first.<br>
Ex.2: Ranking the recommendations will help.</p>
<h4 id="Step-3:-What-data-is-needed-to-take-those-actions?">
<a class="anchor" href="#Step-3:-What-data-is-needed-to-take-those-actions?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 3: What data is needed to take those actions?<a class="anchor-link" href="#Step-3:-What-data-is-needed-to-take-those-actions?"> </a>
</h4>
<p>If you don't have the data, you'll need to get it ... because the data pulls the levers which get you closer to your objective(s).</p>
<p>Ex.1: Seeing what how pages linked to other pages.<br>
Ex.2: Collecting data on what customers purchased, what was recommended, and what they did with that info.</p>
<h4 id="Step-4:-Build-models">
<a class="anchor" href="#Step-4:-Build-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 4: Build models<a class="anchor-link" href="#Step-4:-Build-models"> </a>
</h4>
<p>Only once you have the data and know what actions you want to be able to take based on the information within it, do you being modeling ... first, defining what models you can even build with that data and second, what data you need to collect for models you can't.</p>
<p>Ex.1: A model that takes the page relation data and predicts a ranking given a query.<br>
Ex.2: Two models that predict the purchasing proabilities conditional on seeing or not seeing a recommendation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="How-to-Avoid-Disaster">
<a class="anchor" href="#How-to-Avoid-Disaster" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to Avoid Disaster<a class="anchor-link" href="#How-to-Avoid-Disaster"> </a>
</h2>
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>Your model is only as good as the data it was trained on
</div>
<p>Two problems to watch out for:</p>
<ol>
<li>
<strong>out-of-domain data</strong>: "data that our model sees in production that is very different to what it saw during training.</li>
<li>
<strong>domain shift</strong>: "whereby the type of data that our model sees changes over time."</li>
</ol>
<p>Mitigation steps:</p>
<p><img src="https://raw.githubusercontent.com/ohmeow/ohmeow_website/master/images/articles/avoid-disaster-steps.png" alt=""></p>
<p>"Where possible, the <strong>first step</strong> is to use an entirely manual process with your model running in parallel and not being used to directly drive any actions."</p>
<p>"The <strong>second step</strong> is to try and limit the scope of the model."</p>
<p>"The <strong>third step</strong> is to gradually increase the scope of your rollout."
</p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>"Try to think about all the ways in which your system could go wrong, and then think about what measure or report or picture could reflect that problem, and ensure that your regular reporting includes that information."
</div>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Defining good validation and tests sets are part of the solution. See my "<a href="https://ohmeow.com/what-is/training-validation-test-sets#How-to-create-good-validation-and-test-sets">How to create good validation and test sets</a>" for more details.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Getting-help">
<a class="anchor" href="#Getting-help" aria-hidden="true"><span class="octicon octicon-link"></span></a>Getting help<a class="anchor-link" href="#Getting-help"> </a>
</h2>
<p>A few of ways ...</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>download_images<span class="o">?</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>download_images<span class="o">??</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">doc</span><span class="p">(</span><span class="n">download_images</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can also use <code>pdb.set_trace</code> (in code) or  <code>%debug</code>(in a new cell following the one with the error) to step through your code.  I use the former all the time ... its a great way to debug and also learn what the code is doing and why.  For example, I use it to look at the shape of things as the travel through and out of different layers in my NNs.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pdb</span>
<span class="k">def</span> <span class="nf">div_by_zero</span><span class="p">():</span>
  <span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>
  <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">0</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'here'</span><span class="p">)</span>

<span class="c1"># uncomment this to see what I'm talking about ...</span>
<span class="c1"># div_by_zero()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Getting-and-cleaning-your-images">
<a class="anchor" href="#Getting-and-cleaning-your-images" aria-hidden="true"><span class="octicon octicon-link"></span></a>Getting and cleaning your images<a class="anchor-link" href="#Getting-and-cleaning-your-images"> </a>
</h2>
<ol>
<li>Use <code>download_images</code> listed as URLs in a text file <code>urls</code> to download the actual images locally.  </li>
<li>Get the file path to the images via <code>get_image_files</code> in an <code>L</code> object.  </li>
<li>Get rid of the corrupt images using <code>verify_images</code> and <code>Path.unlink</code>.</li>
</ol>

<pre><code>path = Path('bears/grizzly')
download_images(path, urls=image_urls.txt)

file_paths = get_image_files(path)
failed = verify_images(file_paths)
failed.map(Path.unlink)</code></pre>
<p>Notice how <code>L</code>'s <code>map</code> method is used to apply the <code>Path.unlink</code> function to each item in-place.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="DataBlock-API-Basics">
<a class="anchor" href="#DataBlock-API-Basics" aria-hidden="true"><span class="octicon octicon-link"></span></a>DataBlock API Basics<a class="anchor-link" href="#DataBlock-API-Basics"> </a>
</h2>
<p>The <strong>DataBlock API</strong> represents fastai's high-level approach for building <strong>DataLoaders</strong> from your raw data sources. It is a reusable blueprint for how data is used both during model training and at inference time, and along with the fastai callback system, it represents one of the core pieces of the fastai framework.</p>
<p>"<strong>... a <code>DataBlock object</code> ... is like a template for creating a <code>DataLoaders</code> object</strong>"</p>
<p>"A <code>DataLoader</code> is a class that provides batches of a few items at a time to the GPU"</p>
<h3 id='Defining-your-"blueprint"-using-the-DataBlock-API'>
<a class="anchor" href="#Defining-your-" blueprint aria-hidden="true"><span class="octicon octicon-link"></span></a>Defining your "blueprint" using the DataBlock API<a class="anchor-link" href="#Defining-your-%22blueprint%22-using-the-DataBlock-API"> </a>
</h3>
<p>There are <strong>four</strong> things you need to specify to make your data usable for training (e.g., to build at minimum a training and validation <code>DataLoader</code>).</p>
<ol>
<li>What <strong>kind of data</strong> you are working with</li>
<li>How to <strong>get</strong> the data</li>
<li>How to <strong>label</strong> the data</li>
<li>How to <strong>create a validation set</strong>
</li>
</ol>
<p>Here's an example of how this is done with the <code>DataBlock API</code>:</p>

<pre><code>d_block = DataBlock(
  blocks=(ImageBlock, CategoryBlock),              #=&gt; our independent and dependent variable datatypes
  get_items=get_image_files,                       #=&gt; how to get our data
  splitter=RandomSplitter(valid_pct=0.2, seed=42), #=&gt; how to create the validation set
  get_y=parent_label,                              #=&gt; how to label our data
  item_tfms=Resize(128))                           #=&gt; code that runs against each item as it is fetched</code></pre>
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Use the <code>seed</code> argument to ensure you get the same training/validation set each time you run that code; else you won’t be able to know if, as you change hyperparameter values, your model performance changed because of those values and/or because of difference in your training/validation sets!
</div>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>To ensure reproducibility in your fastai training, follow the tips/tricks laid out in the <a href="https://forums.fast.ai/t/solved-reproducibility-where-is-the-randomness-coming-in/31628">Reproducibility: Where is the randomness coming in?</a> forum post.
</div>
<h3 id='Using-your-"blueprint"-to-build-your-DataLoaders'>
<a class="anchor" href="#Using-your-" blueprint aria-hidden="true"><span class="octicon octicon-link"></span></a>Using your "blueprint" to build your <code>DataLoaders</code><a class="anchor-link" href="#Using-your-%22blueprint%22-to-build-your-DataLoaders"> </a>
</h3>
<p>Once you've defined your blueprint for how to get your modelable data (i.e., your <code>DataLoaders</code>), you need to pass it the "actual source" of your data, which can be a path or a DataFrame or whatever.</p>

<pre><code>dls = d_block.dataloaders(path)</code></pre>
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Use <code>dls.show_batch(...)</code> or <code>dls.valid.show_batch(...)</code> to visualize your training/validation data.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Transforms">
<a class="anchor" href="#Transforms" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transforms<a class="anchor-link" href="#Transforms"> </a>
</h2>
<p>The DataBlock API relies heavily on the use of fastai <strong>transforms</strong>. They are used in the <code>blocks</code> you see above as well as inline, as you'll see below.</p>
<h3 id='What-is-a-"Transform"?'>
<a class="anchor" href="#What-is-a-" transform aria-hidden="true"><span class="octicon octicon-link"></span></a>What is a "Transform"?<a class="anchor-link" href="#What-is-a-%22Transform%22?"> </a>
</h3>
<p>A <strong><em>Transform</em></strong> contains code that is applied automatically during training.</p>
<h3 id="What-kinds-of-transforms-are-there?">
<a class="anchor" href="#What-kinds-of-transforms-are-there?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What kinds of transforms are there?<a class="anchor-link" href="#What-kinds-of-transforms-are-there?"> </a>
</h3>
<p>There are <strong>two</strong> kinds of transforms:</p>
<p><strong>Item Transforms</strong>: Applied to each individual item in your dataset, they are applied to an item from your dataset when it is fetched.
</p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Use the <code>item_tfms</code> argument to define your batch transforms. It is more technically correct to think of them as your <em>after batch</em> transforms since that is whey they are applied
</div>
<p><strong>Batch Transforms</strong>: Applied to a <em>batch of items</em> using the GPU, they are applied to a collection of items on the GPU <em>after</em> they have been collated into the same shape.
</p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Use the <code>batch_tfms</code> argument to define your batch transforms. It is more technically correct to think of them as your <em>after batch</em> transforms since that is whey they are applied
</div>
<p>An example:</p>

<pre><code>d_block = d_block.new(item_tfms=RandomResizedCrop(128, min_scale=0.3), batch_tfms=aug_transforms(mult=2))</code></pre>
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong><code>aug_transforms</code> are "a standard set of augmentations that we have found work pretty well"
</div>
<h3 id="When-should-I-use-an-item-transform?">
<a class="anchor" href="#When-should-I-use-an-item-transform?" aria-hidden="true"><span class="octicon octicon-link"></span></a>When should I use an <strong>item transform</strong>?<a class="anchor-link" href="#When-should-I-use-an-item-transform?"> </a>
</h3>
<p>TODO</p>
<h3 id="When-should-I-use-a-batch-transform?">
<a class="anchor" href="#When-should-I-use-a-batch-transform?" aria-hidden="true"><span class="octicon octicon-link"></span></a>When should I use a <strong>batch transform</strong>?<a class="anchor-link" href="#When-should-I-use-a-batch-transform?"> </a>
</h3>
<h4 id="Data-augmentation">
<a class="anchor" href="#Data-augmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data augmentation<a class="anchor-link" href="#Data-augmentation"> </a>
</h4>
<p><strong>Data augmentation</strong> transorms (e.g., rotation, flipping, perspective warping, brightness changes, contrast changes, etc...) are defined as <strong>batch transforms</strong> and run on the GPU.</p>
<h3 id="Tips-&amp;-Tricks">
<a class="anchor" href="#Tips-&amp;-Tricks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tips &amp; Tricks<a class="anchor-link" href="#Tips-&amp;-Tricks"> </a>
</h3>
<h4 id="1.-Changing-your-transforms-without-having-to-redefine-your-DataBlock-from-scratch">
<a class="anchor" href="#1.-Changing-your-transforms-without-having-to-redefine-your-DataBlock-from-scratch" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Changing your transforms without having to redefine your DataBlock from scratch<a class="anchor-link" href="#1.-Changing-your-transforms-without-having-to-redefine-your-DataBlock-from-scratch"> </a>
</h4>
<p>You can change the transforms in your DataBlock by reusing an existing DataBlock via <code>d_block.new</code>.</p>

<pre><code>d_block = d_block.new(item_tfms=Resize(128, ResizeMethod.squish))
dls = d_block.dataloaders(path)
...
d_block = d_block.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode='zeroes'))
dls = d_block.dataloaders(path)
...</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="How-to-train-an-image-classification-model-with-the-high-level-API">
<a class="anchor" href="#How-to-train-an-image-classification-model-with-the-high-level-API" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to train an image classification model with the high-level API<a class="anchor-link" href="#How-to-train-an-image-classification-model-with-the-high-level-API"> </a>
</h2>
<h3 id="Step-1:-Get-your-data">
<a class="anchor" href="#Step-1:-Get-your-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 1: Get your data<a class="anchor-link" href="#Step-1:-Get-your-data"> </a>
</h3>
<p>We can grab all kinda of useful datasets via the <a href="https://course.fast.ai/datasets">fast.ai Datasets</a> for various tasks and data types (e.g., images, text, etc...).  In this example we'll work with the <code>Imagnette</code> dataset, a "subset of 10 easily classified classes from Imagenet."
</p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Working with a representative subset of your full dataset is recommended for experimentation and as a means to verify your data prep and model training.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll use <code>untar_data</code> to both download and decompress the dataset.  It will return a <code>Pathlib</code> object pointing to where the data has been downloaded</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_data_path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">IMAGENETTE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">raw_data_path</span><span class="p">)</span>
<span class="n">raw_data_path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use <code>get_image_files()</code> to grab all the image filepaths in the training set. This method takes a path as an argument and recursively grabs all the images in that path by default.</p>
<p>We'll need to know how to infer the class for each image and this can be done by looking at one or more of the actual image filepaths.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">files</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">raw_data_path</span><span class="o">/</span><span class="s1">'train'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">files</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we can see that the convention followed for this dataset is having the class Id we want to predict in its parent folder, while each image's unique name is the class_id followed by a unique identifier: <code>{class_id}/{class_id}_{unique_id}.JPEG</code>.</p>
<p>We can validate this by ensure we see 10 parent folders ...</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">raw_data_path</span><span class="o">/</span><span class="s1">'train'</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can even look at one or more of the images using the <code>PIL</code> package</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">files</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">img</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-2:-Build-your-DataBlock">
<a class="anchor" href="#Step-2:-Build-your-DataBlock" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 2: Build your <code>DataBlock</code><a class="anchor-link" href="#Step-2:-Build-your-DataBlock"> </a>
</h3>
<p>The objective here is to ultimately be able to build <code>DataLoaders</code> you can feed into your model.  There are a variety of ways to do this but the recommended go to is to use the mid-level <code>DataBlock API</code> if you can.  A <code>DataBlock</code> represents a blueprint for building <code>DataLoaders</code> from your raw data, whereas the <code>DataLoaders</code> are what allow us to feed our examples into our model a mini-batch (a few) at a time.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">ImageBlock</span><span class="p">,</span> <span class="n">CategoryBlock</span><span class="p">),</span>              <span class="c1"># tell the block what are INPUTS/TARGETS are (images and a category/class here)</span>
    <span class="n">get_items</span><span class="o">=</span><span class="n">get_image_files</span><span class="p">,</span>                       <span class="c1"># tell the block HOW TO GET THE DATA (here its files but could also be rows in a .csv, etc...)</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="n">valid_pct</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="c1"># tell the block HOW TO BUILD THE VALIDATION SET (here we just randomly select 20% data)</span>
    <span class="n">get_y</span><span class="o">=</span><span class="n">parent_label</span><span class="p">,</span>                              <span class="c1"># tell the block WHERE TO GET OUR LABELS (here from the parent folder)</span>
    <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>                            <span class="c1"># tell the block things WE WANT DONE EACH TIME WE GRAB AN ITEM from the dataset</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you're unsure what any of these classes or methods do, don't forget about the <code>??</code> syntax you can use in notebooks.  For example ...</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>ImageBlock<span class="o">??</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>We specify <code>Resize(128)</code> as an <strong>item transform</strong> because ultimately we’ll feed the data into our model a <em>mini-batch</em> at a time, and in order to take advantage of the GPU and tensor operations that items we feed in need to be the same size.
</div>
<p>"<strong><em>Item transforms</em></strong> are pieces of code that run on each individual item, whether it be an image, category, or so forth."</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">raw_data_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We <em>implement</em> our blueprint by passing the path to the image files into the <code>DataBlock.dataloaders()</code> method. Whatever we pass in as an argument here, gets passed to the function we specified in <code>get_items</code> above (which is<code>get_image_files</code> in this case). While iterating over each image, <code>get_y</code> will be used to grab the label of the image and our two blocks, <code>ImageBlock</code> and <code>CategoryBlock</code> will provide both the pre and post-processing necessary to work with our images and classes.  Finally, our <code>splitter</code> will randomly take 20% of the dataset and set it aside for our validation set.
</p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>You want to ensure you get the same validation set each time so you can meaningfully assess the performance of your model(s) as you tweak things.  You do this by assigning a <code>seed</code>.  If you don’t do this, you won’t know if your model’s performance is due to it seeing different images in the validation set or because of change you’ve made in your hyperparameters, model architecture, etc...
</div>
<p>Each time we grab an image, regardless of the size, from the dataset, we resize it as a 128x128 tensor.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use the <code>DataBlock.new()</code> method to modify only parts of our <code>DataBlock</code> defined above, and so create a new instance.  Here for example, we can change how the <code>Resize</code> transform resizes images so that it randomly crops the image, keeping at least 30% of the image each time.</p>
<p>By default, this method crops the images to fit a square (but as you can see here we can also have fastai pad the images with zeroes, squish, or stretch them.).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dblock2</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">item_tfms</span><span class="o">=</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">min_scale</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">dblock2</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">raw_data_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">valid</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>When dealing with data augmentation, its often helpful to see how a <strong><em>single</em></strong> example is augmented.
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">unique</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using <code>RandomResizedCrop</code> allows " our model can learn to focus on, and recognize, different features in our images. It also reflects how images work in the real world: different photos of the same thing may be framed in slightly different ways."
</p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>"...training the neural network with examples of images where the objects are in slightly different places and slightly different sizes helps it to understand the basic concept of what an object is, and how it can be represented in an image." 
</div>
<p>We can, and should, also use <strong>data augmentation</strong> to create "random variations"  that are representative of what our model will see in the wild.  "Examples of common data augmentation techniques for images are rotation, flipping, perspective warping, brightness changes and contrast changes."</p>
<p>For "natural photos", fastai provides the <code>aug_tranforms()</code> method that have proven to work well in general.</p>
<p>In addition, such "data augmentations" are tyically desirable to have run on the GPU since they'll run much faster.  To make this happen, these "transforms" are specified as <code>batch_tfms</code> since them happen on a "mini-batch" at a time.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dblock2</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span> <span class="n">batch_tfms</span><span class="o">=</span><span class="n">aug_transforms</span><span class="p">(</span><span class="n">mult</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">dblock2</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">raw_data_path</span><span class="p">)</span>
<span class="n">dls</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">unique</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using the <code>unique=True</code> argument with our <code>DataLoaders.show_batch()</code> method allows us to see how these augmentations are applied to a single image.
</p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Verify that the augmentations you use are representative of what your model will see in the wild
</div>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Use augmentations to artificially provide more images than you do in your raw dataset
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-3:-Train-your-model">
<a class="anchor" href="#Step-3:-Train-your-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 3: Train your model<a class="anchor-link" href="#Step-3:-Train-your-model"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dblock</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">new</span><span class="p">(</span>
    <span class="n">item_tfms</span><span class="o">=</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="n">min_scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">batch_tfms</span><span class="o">=</span><span class="n">aug_transforms</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">raw_data_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">interp</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
<span class="n">interp</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>"It’s helpful to see where exactly our errors are occurring, to see whether they’re due to a dataset problem (e.g., images that aren’t bears at all, or are labeled incorrectly, etc.), or a model problem (perhaps it isn’t handling images taken with unusual lighting, or from a different angle, etc.). To do this, we can sort our images by their loss."
</div>
<p>For each image shown, <code>ClassificationInterpretation.plot_top_losses()</code> shows four things: the predicted class, the actual class, the loss, and the probability</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">interp</span><span class="o">.</span><span class="n">plot_top_losses</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>" a model can actually help you find data issues more quickly and easily. So, we normally prefer to train a quick and simple model first, and then use it to help us with data cleaning."
</div>
<p>fastai includes the <code>ImageClassifierCleaner</code> that can be used to "clean your dataset" (remove or re-label images).  See chapter 2 for more information on how to use this utility.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Step-4:-Inference">
<a class="anchor" href="#Step-4:-Inference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 4: Inference<a class="anchor-link" href="#Step-4:-Inference"> </a>
</h3>
<p>"Remember that a model consists of two parts: the architecture and the trained parameters. The easiest way to save the model is to save both of these, because that way when you load a model you can be sure that you have the matching architecture and parameters."</p>
<p>How do we do this?  We use <code>Learner.export()</code>.</p>
<p>By using this method we don't have to redefine how the data needs to be transformed as the inference learner will know what transforms to apply based on what was applied to your validation <code>DataLoader</code>. For example, it will know <strong><em>not</em></strong> to apply any data augmentation which is only really useful during training.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">()</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">()</span>
<span class="n">path</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="n">file_exts</span><span class="o">=</span><span class="s1">'.pkl'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn_inf</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'export.pkl'</span><span class="p">)</span>
<span class="n">learn_inf</span><span class="o">.</span><span class="n">dls</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Calling <code>Learner.predict()</code> will return the predicated label, the label index in the vocab, and the probabilities assigned to each of our 10 labels.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn_inf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">files</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Inference">
<a class="anchor" href="#Inference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Inference<a class="anchor-link" href="#Inference"> </a>
</h2>
<p><strong>Inference</strong> is about how you used your trained model to get predictions on new data. It is often structured to perform in real-time on a single (or at least a small set of data) item or in the background where large quantities of data can be processed together in batches.  For the former, we can use fastai's <code>Learner.predict()</code> method while for the later we can use either fastai's <code>Learner.get_preds()</code> or write our own inference loop using PyTorch.</p>
<h3 id="export()-and-predict()">
<a class="anchor" href="#export()-and-predict()" aria-hidden="true"><span class="octicon octicon-link"></span></a><code>export()</code> and <code>predict()</code><a class="anchor-link" href="#export()-and-predict()"> </a>
</h3>
<p>"a model consists of two parts: the <em>architecture</em> and the trained <em>parameters</em>." You can use it just like any other function</p>

<pre><code># saves the architecture, the trained parameters, and the definintion of how to create your DataLoaders
learn.export()</code></pre>
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>fastai ... uses your validation set <code>DataLoader</code> for inference by default, <strong><em>so your data augmentation will not be applied.</em></strong>
</div>

<pre><code>inf_learn = load_learner(path/'export.pkl')
inf_learn.predict('images/grizzly.jpg')
inf_learn.dls.vocab # =&gt; To view possible classification categories/labels</code></pre>
<p>For options on how to deploy your app, see the <a href="https://course.fast.ai/">Deployment section</a> in the course website. I personally like to use <a href="https://fastapi.tiangolo.com/">FastAPI</a> and there is a good <a href="https://forums.fast.ai/t/fastai2-fastapi-starter-template/69373?u=wgpubs">starter template here</a> for that.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Resources">
<a class="anchor" href="#Resources" aria-hidden="true"><span class="octicon octicon-link"></span></a>Resources<a class="anchor-link" href="#Resources"> </a>
</h2>
<ol>
<li>
<p><a href="https://book.fast.ai">https://book.fast.ai</a> - The book's website; it's updated regularly with new content and recommendations from everything to GPUs to use, how to run things locally and on the cloud, etc...</p>
</li>
<li>
<p><a href="https://docs.fast.ai/">https://docs.fast.ai/</a> - The library's documentation; includes tutorials and other tips for development.</p>
</li>
<li>
<p><a href="https://forums.fast.ai/">https://forums.fast.ai/</a> - If you're not part of the community yet, you should be. Before posting a question, search to see if it has been answered already (95% of the time, it has).</p>
</li>
</ol>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="ohmeow/ohmeow_website"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/posts/2020/11/16/ajtfb-chapter-2.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p>A full-stack web application and ML development company.</p>
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a class="fa-icon" rel="me" href="mailto:wgilliam@ohmeow.com" title="wgilliam@ohmeow.com"><i class="far fa-envelope"></i></a></li><li><a rel="me" href="https://github.com/ohmeow" title="ohmeow"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/waydegilliam" title="waydegilliam"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul></div>

  </div>

</footer>

<script>
  // method will ensure the floating header isn't covering the note header
  function goToNote(elId) {
    const el = document.getElementById(elId);
    const elPos = el.getBoundingClientRect().top + document.documentElement.scrollTop;
      
    window.focus();
    window.scrollTo(0, elPos - 90);
  }

  // ensure target note shows below floating header on # change
  window.addEventListener("hashchange", (ev) => { 
    const hash = ev.target.location.hash
    if (hash) {
      goToNote(hash.substring(1))
    }
  });

  // onload, ensure note shows below floating header
  window.addEventListener("load", (ev) => { 
    const hash = ev.target.location.hash
    if (hash) {
      goToNote(hash.substring(1))
    }
  });
</script></body>

</html>
