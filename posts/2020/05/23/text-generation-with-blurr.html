<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Summarization with blurr | ohmeow</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Summarization with blurr" />
<meta name="author" content="Wayde Gilliam" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="blurr is a libray I started that integrates huggingface transformers with the world of fastai v2, giving fastai devs everything they need to train, evaluate, and deploy transformer specific models. In this article, I provide a simple example of how to use blurr’s new summarization capabilities to train, evaluate, and deploy a BART summarization model." />
<meta property="og:description" content="blurr is a libray I started that integrates huggingface transformers with the world of fastai v2, giving fastai devs everything they need to train, evaluate, and deploy transformer specific models. In this article, I provide a simple example of how to use blurr’s new summarization capabilities to train, evaluate, and deploy a BART summarization model." />
<link rel="canonical" href="https://ohmeow.com/posts/2020/05/23/text-generation-with-blurr.html" />
<meta property="og:url" content="https://ohmeow.com/posts/2020/05/23/text-generation-with-blurr.html" />
<meta property="og:site_name" content="ohmeow" />
<meta property="og:image" content="https://ohmeow.com/images/articles/blurr-logo-small.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-23T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://ohmeow.com/posts/2020/05/23/text-generation-with-blurr.html","headline":"Summarization with blurr","dateModified":"2020-05-23T00:00:00-05:00","datePublished":"2020-05-23T00:00:00-05:00","image":"https://ohmeow.com/images/articles/blurr-logo-small.png","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://ohmeow.com/posts/2020/05/23/text-generation-with-blurr.html"},"author":{"@type":"Person","name":"Wayde Gilliam"},"description":"blurr is a libray I started that integrates huggingface transformers with the world of fastai v2, giving fastai devs everything they need to train, evaluate, and deploy transformer specific models. In this article, I provide a simple example of how to use blurr’s new summarization capabilities to train, evaluate, and deploy a BART summarization model.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ohmeow.com/feed.xml" title="ohmeow" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-163296836-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

    <div class="wrapper"><a class="site-title" rel="author" href="/"><img style="height: 60px;" src="/images/ohmeow_logo.png" alt="ohmeow.com"></a><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger" />
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
              </svg>
            </span>
          </label>
  
          <div class="trigger"><a class="page-link" href="/about/"><span class="top-menu-text">About Me</span></a><a class="page-link" href="/search/"><span class="top-menu-text">Search</span></a><a class="page-link" href="/categories/"><span class="top-menu-text">Tags</span></a></div>
        </nav></div>
  </header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Summarization with blurr</h1><p class="page-description">blurr is a libray I started that integrates huggingface transformers with the world of fastai v2, giving fastai devs everything they need to train, evaluate, and deploy transformer specific models.  In this article, I provide a simple example of how to use blurr's new summarization capabilities to train, evaluate, and deploy a BART summarization model.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-05-23T00:00:00-05:00" itemprop="datePublished">
        May 23, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Wayde Gilliam</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      20 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#fastai">fastai</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#huggingface">huggingface</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#blurr">blurr</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#summarization">summarization</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#text generation">text generation</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/ohmeow/ohmeow_website/tree/master/_notebooks/2020-05-23-text-generation-with-blurr.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/ohmeow/ohmeow_website/master?filepath=_notebooks%2F2020-05-23-text-generation-with-blurr.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/ohmeow/ohmeow_website/blob/master/_notebooks/2020-05-23-text-generation-with-blurr.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-05-23-text-generation-with-blurr.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># !pip install ohmeow-blurr -q</span>
<span class="c1"># !pip install datasets -q</span>
<span class="c1"># !pip install bert-score -q</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">datasets</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span> <span class="nn">blurr.data.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">blurr.modeling.all</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[nltk_data] Downloading package wordnet to /root/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-Preparation">Data Preparation<a class="anchor-link" href="#Data-Preparation"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We're going to use to use the  <a href="https://huggingface.co/datasets">datasets</a> library from huggingface to grab your raw data.  This package gives you access to all kinds of NLP related datasets, explanations of each, and various task specific metrics to use in evaluating your model.  The best part being everything comes down to you in JSON!  This makes it a breeze to get up and running quickly!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll just use a subset of the training set to build both our training and validation DataLoaders</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;cnn_dailymail&#39;</span><span class="p">,</span> <span class="s1">&#39;3.0.0&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train[:1%]&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Reusing dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">raw_data</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article</th>
      <th>highlights</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force "to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction." It's a step that is set to turn an internat...</td>
      <td>Syrian official: Obama climbed to the top of the tree, "doesn't know how to get down"\nObama sends a letter to the heads of the House and Senate .\nObama to seek congressional approval on military action against Syria .\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .</td>
      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...</td>
      <td>Usain Bolt wins third gold of world championship .\nAnchors Jamaica to 4x100m relay victory .\nEighth gold at the championships for Bolt .\nJamaica double up in women's 4x100m relay .</td>
      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Kansas City, Missouri (CNN) -- The General Services Administration, already under investigation for lavish spending, allowed an employee to telecommute from Hawaii even though he is based at the GSA's Kansas City, Missouri, office, a CNN investigation has found. It cost more than $24,000 for the business development specialist to travel to and from the mainland United States over the past year. He is among several hundred GSA "virtual" workers who also travel to various conferences and their home offices, costing the agency millions of dollars over the past three years. Under the program, ...</td>
      <td>The employee in agency's Kansas City office is among hundreds of "virtual" workers .\nThe employee's travel to and from the mainland U.S. last year cost more than $24,000 .\nThe telecommuting program, like all GSA practices, is under review .</td>
      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Los Angeles (CNN) -- A medical doctor in Vancouver, British Columbia, said Thursday that California arson suspect Harry Burkhart suffered from severe mental illness in 2010, when she examined him as part of a team of doctors. Dr. Blaga Stancheva, a family physician and specialist in obstetrics, said both Burkhart and his mother, Dorothee, were her patients in Vancouver while both were applying for refugee status in Canada. "I was asked to diagnose and treat Harry to support a claim explaining why he was unable to show up in a small-claims court case," Stancheva told CNN in a phone intervie...</td>
      <td>NEW: A Canadian doctor says she was part of a team examining Harry Burkhart in 2010 .\nNEW: Diagnosis: "autism, severe anxiety, post-traumatic stress disorder and depression"\nBurkhart is also suspected in a German arson probe, officials say .\nProsecutors believe the German national set a string of fires in Los Angeles .</td>
      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>
    </tr>
    <tr>
      <th>4</th>
      <td>(CNN) -- Police arrested another teen Thursday, the sixth suspect jailed in connection with the gang rape of a 15-year-old girl on a northern California high school campus. Jose Carlos Montano, 18, was arrested on charges of felony rape, rape in concert with force, and penetration with a foreign object, said Richmond Police Lt. Mark Gagan. Montano was arrested Thursday evening in San Pablo, California, a small town about two miles from the city of Richmond, where the crime took place. Montano, who was held in lieu of $1.3 million bail, is accused of taking part in what police said was a 2½...</td>
      <td>Another arrest made in gang rape outside California school .\nInvestigators say up to 20 people took part or stood and watched the assault .\nFour suspects appeared in court Thursday; three wore bulletproof vests .</td>
      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We begin by getting our hugginface objects needed for this task (e.g., the architecture, tokenizer, config, and model).  We'll use blurr's <code>get_hf_objects</code> helper method here.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;facebook/bart-large-cnn&quot;</span>
<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> 
                                                                               <span class="n">model_cls</span><span class="o">=</span><span class="n">BartForConditionalGeneration</span><span class="p">)</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;bart&#39;,
 transformers.models.bart.configuration_bart.BartConfig,
 transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,
 transformers.models.bart.modeling_bart.BartForConditionalGeneration)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we need to build out our DataBlock.  Remember tha a DataBlock is a blueprint describing how to move your raw data into something modelable.  That blueprint is executed when we pass it a data source, which in our case, will be the DataFrame we created above. We'll use a random subset to get things moving along a bit faster for the demo as well.</p>
<p>Notice that the blurr DataBlock as been dramatically simplified given the shift to on-the-fly batch-time tokenization.  All we need is to define a single <code>HF_Seq2SeqBeforeBatchTransform</code> instance, optionally passing a list to any of the tokenization arguments to differentiate the values for the input and summary sequences.  In addition to specifying a custom max length for the inputs, we can also do the same for the output sequences ... and with the latest release of blurr, we can even customize the text generation by passing in <code>text_gen_kwargs</code>.</p>
<p>We pass <code>noop</code> as a type transform for our targets because everything is already handled by the batch transform now.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="n">default_text_gen_kwargs</span><span class="p">(</span><span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;summarization&#39;</span><span class="p">);</span> <span class="n">text_gen_kwargs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;bad_words_ids&#39;: None,
 &#39;bos_token_id&#39;: 0,
 &#39;decoder_start_token_id&#39;: 2,
 &#39;diversity_penalty&#39;: 0.0,
 &#39;do_sample&#39;: False,
 &#39;early_stopping&#39;: True,
 &#39;eos_token_id&#39;: 2,
 &#39;length_penalty&#39;: 2.0,
 &#39;max_length&#39;: 142,
 &#39;min_length&#39;: 56,
 &#39;no_repeat_ngram_size&#39;: 3,
 &#39;num_beam_groups&#39;: 1,
 &#39;num_beams&#39;: 4,
 &#39;num_return_sequences&#39;: 1,
 &#39;pad_token_id&#39;: 1,
 &#39;repetition_penalty&#39;: 1.0,
 &#39;temperature&#39;: 1.0,
 &#39;top_k&#39;: 50,
 &#39;top_p&#39;: 1.0,
 &#39;use_cache&#39;: True}</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hf_batch_tfm</span> <span class="o">=</span> <span class="n">HF_Seq2SeqBeforeBatchTransform</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span> 
                                              <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">max_tgt_length</span><span class="o">=</span><span class="mi">130</span><span class="p">,</span> <span class="n">text_gen_kwargs</span><span class="o">=</span><span class="n">text_gen_kwargs</span><span class="p">)</span>

<span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">HF_Seq2SeqBlock</span><span class="p">(</span><span class="n">before_batch_tfm</span><span class="o">=</span><span class="n">hf_batch_tfm</span><span class="p">),</span> <span class="n">noop</span><span class="p">)</span>

<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;article&#39;</span><span class="p">),</span> <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;highlights&#39;</span><span class="p">),</span> <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">dls</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">items</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">dls</span><span class="o">.</span><span class="n">valid</span><span class="o">.</span><span class="n">items</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2297, 574)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's always a good idea to check out a batch of data and make sure the shapes look right.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, torch.Size([2, 256]), torch.Size([2, 77]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Even better, we can take advantage of blurr's TypeDispatched version of <code>show_batch</code> to look at things a bit more intuitively.  We pass in the <code>dls</code> via the <code>dataloaders</code> argument so we can access all tokenization/modeling configuration stored in our batch transform above.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The news from Pakistan is generally bad news. In the past week, which was far from atypical, suicide bombers attacked a court building in the northwestern city of Peshawar taking hostages and killing four people. In the southern city of Karachi the director of a renowned social program working in the megacity's poorest neighborhoods was shot and killed. And gunmen kidnapped two female Czech tourists in southwestern Pakistan. But this past week also saw more than a glimmer of good news from Pakistan: Saturday, March 16 marked an extraordinary moment in Pakistani history, as this is the first time  a civilian government has served its entire five-year term (from 2008 to 2013). And, for the first time in its history, the Pakistani military appears unwilling to mount a coup against the civilian government. The military has successfully executed three coups and attempted a number of others since Pakistan's independence in 1947. Today the army understands that the most recent coup by General Pervez Musharraf who took power in 1999 has tarnished its brand. Musharraf hung on to power for almost a decade and his imposition of emergency rule in 2007 triggered massive street protests and eventually his ouster. On Saturday, Musharaf announced he is returning to Pakistan from self-imposed exile on March 24 to</td>
      <td>Peter Bergen: For the first time, Pakistan government served its full term.\nHe says lack of military coup attempt shows government is more stable than many think.\nElections in Pakistan, Afghanistan likely to be crucial for those two nations.\nBergen: He says Afghan economy is resilient and corruption may be receding.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GALVESTON, Texas (CNN)  -- Rescuers in Galveston, Texas, were going door-to-door Saturday to check on the estimated 20,000 people who failed to flee Hurricane Ike, which has slowed to tropical storm status. Park benches are strewn about in downtown Houston Saturday during Hurricane Ike. As of Saturday afternoon, the Galveston Fire Department had taken 27 people to a shelter in a high school on the coastal island, which was without electricity or water pressure. No casualties had been discovered so far in the search and rescue efforts, which have been hampered by heavy flooding and scattered debris. Galveston had ordered evacuation of the island, but Galveston City Manager Steve LeBlanc said about 40 percent of the city's 57,523 residents chose to stay. LeBlanc said the island would be closed while authorities assess damages, including to the causeway, which was in "bad shape" because of debris and road damage. "The road buckled in a number of places," LeBlanc said. "Even if we opened it up you couldn't get through." LeBlanc said 17 buildings on the island had been destroyed by fires, potent winds and a strong storm surge. "We are in</td>
      <td>NEW: Wreckage impedes rescue efforts, adding to uncertainty about survivors.\nTexas woman wonders whether it was worth it to ride out storm in home.\nFour deaths in Texas attributed to Ike, now a tropical storm with 45 mph winds.\n2.6 million affected by power outages, U.S. Energy Department says.</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training">Training<a class="anchor-link" href="#Training"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll prepare our BART model for training by wrapping it in blurr's <code>HF_BaseModelWrapper</code> object and using the callback, <code>HF_BaseModelCallback</code>, as usual.  A new <code>HF_Seq2SeqMetricsCallback</code> object allows us to specify Seq2Seq metrics we want to use, things like rouge and bertscore for tasks like summarization as well as metrics such as meteor, bleu, and sacrebleu for translations tasks. Using huggingface's metrics library is as easy as specifying a metrics configuration such as below.</p>
<p>Once we have everything in place, we'll freeze our model so that only the last layer group's parameters of trainable.  See <a href="https://docs.fast.ai/basic_train.html#Discriminative-layer-training">here</a> for our discriminitative learning rates work in fastai.</p>
<p><strong>Note:</strong> This has been tested with ALOT of other Seq2Seq models; see the docs for more information.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seq2seq_metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;rouge&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;compute_kwargs&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;rouge_types&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">],</span> <span class="s1">&#39;use_stemmer&#39;</span><span class="p">:</span> <span class="kc">True</span> <span class="p">},</span>
            <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s1">&#39;bertscore&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;compute_kwargs&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;lang&#39;</span><span class="p">:</span> <span class="s1">&#39;en&#39;</span> <span class="p">},</span>
            <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">HF_BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
<span class="n">learn_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">HF_BaseModelCallback</span><span class="p">]</span>
<span class="n">fit_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">HF_Seq2SeqMetricsCallback</span><span class="p">(</span><span class="n">custom_metrics</span><span class="o">=</span><span class="n">seq2seq_metrics</span><span class="p">)]</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
                <span class="n">model</span><span class="p">,</span>
                <span class="n">opt_func</span><span class="o">=</span><span class="n">ranger</span><span class="p">,</span>
                <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">(),</span>
                <span class="n">cbs</span><span class="o">=</span><span class="n">learn_cbs</span><span class="p">,</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">seq2seq_splitter</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">))</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>

<span class="n">learn</span><span class="o">.</span><span class="n">create_opt</span><span class="p">()</span> 
<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Still experimenting with how to use fastai's learning rate finder for these kinds of models.  If you all have any suggestions or interesting insights to share, please let me know.  We're only going to train the frozen model for one epoch for this demo, but feel free to progressively unfreeze the model and train the other layers to see if you can best my results below.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">suggestions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.6/dist-packages/fastai/learner.py:54: UserWarning: Could not load the optimizer state.
  if with_opt: warn(&#34;Could not load the optimizer state.&#34;)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=0.06309573650360108, lr_steep=0.5248074531555176)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxddZ3/8dcn+74nXdKmbejOUgqhrUCRXQUEZARRQMBCdfSHOqCDjvpj5qH+dEaHGVxmBEWtICCWggiyKLJUqYV0b7qldE3SJmmz77m5398fuY2hNM3Ncu/JvXk/H488mnty7z3v3N7knXO+53yPOecQEREBiPE6gIiIjB0qBRER6aNSEBGRPioFERHpo1IQEZE+KgUREekT53WAYOTl5bnp06d7HUNEJKKsW7fuiHMufyiPiYhSmD59OqWlpV7HEBGJKGa2f6iP0e4jERHpo1IQEZE+KgUREemjUhARkT4qBRER6aNSEBGRPioFEZExqMvn5+kNFYT78gYRcZ6CiMh44pzjK6s2s2p9JdNyUzmrKDts69aWgojIGPPDP+9m1fpK7r5sdlgLAVQKIiJjyjMbKrn/j7u47qxC7rp4ZtjXH7JSMLOfm1mNmW3ttyzHzP5oZuWBf8NbgSIiY9hbe+v455WbWVKcw3evOwMzC3uGUG4p/BL44HHLvgK84pybBbwSuC0iMu6VVzez/JFSpuQk85ObzyYhzpsdOSFbq3PuDaDuuMXXACsCn68Arg3V+kVEIkVlQzu3PPwW8bEx/PK2RWSlJHiWJdxVNME5dyjw+WFgwkB3NLPlZlZqZqW1tbXhSSciEmZHWzq55eG1tHb5+NWnFlGUm+JpHs8Gml3vwbcDHoDrnHvIOVfinCvJzx/SdOAiIhGhpdPH7b98m8r6dh6+9RzmTcrwOlLYS6HazCYBBP6tCfP6RUTGjG8/v52yqib+56azWDQjx+s4QPhL4Vng1sDntwK/C/P6RUTGhPrWLlatr+CGkqlcMm/APelhF8pDUh8H1gBzzKzCzJYB3wUuM7Ny4NLAbRGRceeJtw/S6fNz67nTvI7yLiGb5sI59/EBvnRJqNYpIhIJfD1+Hv3bfpYU5zB3ovfjCP3pjGYRkTD70/YaKhvaue3cGV5HeQ+VgohImK14cx+FWclcOq/A6yjvoVIQEQmjnYebWbPnKDcvmUZc7Nj7FTz2EomIRLEVa/aRGBfDjedM9TrKCakURETCpKGti6fXV3LNmZPJTvVuKouTUSmIiITJd/6wg64eP8vOL/Y6yoBUCiIiYfDm7iP8pvQgdyydwZyJ6V7HGZBKQUQkxNq7evjKqi1Mz03hny6d7XWck9I1mkVEQuz+P+7kQF0bj9+5hKT4WK/jnJS2FEREQmjTwQYe/stePr6oiPedkut1nEGpFEREQsTvd/zL01vIT0/kq1fM9TpOUFQKIiIh8rtNlZRVNfEvV8wjIyne6zhBUSmIiIRAp6+H77+0i9MKM/jwGZO9jhM0lYKISAg8smY/lQ3tfOWD84iJMa/jBE2lICIyypo6uvnRq7tZOiuP82fleR1nSFQKIiKj7MHX36GhrZt7PxgZg8v9qRREREZRdVMHD/9lL9ecOZnTCjO9jjNkKgURkVH07ee34/fDPZfN8TrKsKgURERGyZ+2VfPspir+z8UzKcpN8TrOsKgURERGQVNHN19/ZitzJ6bzmfef4nWcYdPcRyIio+C7L+ygprmDB285m4S4yP1725PkZvYFM9tqZmVm9kUvMoiIjJY17xzlsbUHWHb+DBZMzfI6zoiEvRTM7DTgTmARsAC4ysxmhjuHiMho2FPbwr1PbaYoJ4W7I3RwuT8vthTmAWudc23OOR/wOnCdBzlERIbN1+Pnwdff4UMPrKahrYv7b1hAcsLYnhY7GF6MKWwFvm1muUA7cAVQ6kEOEZFh2V3TzD1PbmJTRSOXz5/At649jYKMJK9jjYqwl4JzbruZ/TvwMtAKbAR6jr+fmS0HlgMUFRWFNaOIyEAqG9q58aG/4Xfwo08s5MrTJ2EWOXMbDcaTgWbn3MPOubOdcxcA9cCuE9znIedciXOuJD8/P/whRUSO09bl484VpXR2+3ny00u46ozJUVUI4NEhqWZW4JyrMbMiescTlniRQ0QkWH6/454nN7HjcBMP33YOMwvSvY4UEl6dp/BUYEyhG/icc67BoxwiIkF54JVyXth6mK9fOY+L5hR4HSdkPCkF59xSL9YrIjIcz26q4oFXyrn+7CksO3+G13FCKnJPuxMRCYO1e47ypSc3sWhGDt/6yGlRN4ZwPJWCiMgAdte0sPyRdUzJSeahW84mMS7yz0MYjEpBROQEaps7ue0XbxEfa6y4fRFZKQleRwoLTYgnInIcv9/x6UdKOdLSyW+Wv4+pOZE5DfZwqBRERI7z+81VrD/QwPevXxDxE9wNlXYfiYj0093j57/+uIu5E9O5bmGh13HCTqUgItLPU+sq2He0jS9dPoeYmOg+0uhEVAoiIgEd3T088Eo5C4uyuGRe9J6gdjIqBRGRgMfWHuBQYwdfvnxO1J+PMBCVgogI0Nrp48ev7ua8mbmcOzPP6zieUSmIiAAr1uzjaGsXX7o88q+eNhIqBREZ97p7/Kx4cx9LZ+WxsCjb6zieUimIyLj3Utlhqps6ue3c6V5H8ZxKQUTGvV+9uZ+inBQujOIpsYOlUhCRcW1bVRNv7avjliXTiB2H5yUcT6UgIuPaijf3kRwfyw0lU72OMiaoFERk3Kpv7eKZjZVcu7CQzJR4r+OMCSoFERm3flN6kE6fn1vPneZ1lDFDpSAi41KP3/HImv0snpHD3IkZXscZM1QKIjIurS6vpbKhnVt1GOq7qBREZFx6ZkMlmcnx43biu4GoFERk3Gnt9PFSWTVXnD5pXFx3eSg8KQUz+yczKzOzrWb2uJkleZFDRManP26rpr27h4+Mw4voDCbspWBmhcDngRLn3GlALHBjuHOIyPj19IZKCrOSKZk2vuc5OhGvdh/FAclmFgekAFUe5RCRcaa2uZPV5bVcc+bkcXlltcGEvRScc5XA94EDwCGg0Tn38vH3M7PlZlZqZqW1tbXhjikiUeq5zVX4HVyrXUcn5MXuo2zgGmAGMBlINbObj7+fc+4h51yJc64kPz8/3DFFJEo9s6GS+ZMymD0h3esoY5IXu48uBfY652qdc93AKuBcD3KIyDizp7aFTRWNXLtwstdRxiwvSuEAsMTMUqz3IqiXANs9yCEi48wzG6swg6sXaNfRQLwYU1gLrATWA1sCGR4Kdw4RGX9e2V7Nouk5TMzUUfADifNipc65+4D7vFi3iIxfNc2dnF6Y6XWMMU1nNIvIuOCco761i+zUBK+jjGkqBREZF1o6ffj8jpwUlcLJqBREZFyob+0G0JbCIFQKIjIu1LV1AZCtK6ydlEpBRMaF+tZAKWhL4aRUCiIyLtQHthQ0pnByKgURGRfqtKUQFJWCiIwL9W1dxMYYGUmenJ4VMVQKIjIu1LV2k50ST+/sOjIQlYKIjAsNbV1kazxhUCoFERkX6nQ2c1BUCiIyLtS3denIoyCoFERkXKhr7SY7VSeuDUalICJRzzmnMYUgqRREJOo1H5sMT2MKg1IpiEjU65viQlsKg1IpiEjU+/vZzBpTGIxKQUSiXn2bthSCFVQpmFmqmcUEPp9tZlebmSpXRCLCsWspaExhcMFuKbwBJJlZIfAycAvwy1CFEhEZTX1bCiqFQQVbCuacawOuA/7HOXc9cGroYomIjJ661i7iYoz0RE2GN5igS8HM3gfcBDwfWBY7nBWa2Rwz29jvo8nMvjic5xIRCUZ9WxdZKQmaDC8IwdbmF4GvAk8758rMrBh4dTgrdM7tBM4EMLNYoBJ4ejjPJSISjLrWLnJ05FFQgioF59zrwOsAgQHnI865z4/C+i8B3nHO7R+F5xIROaH6tm4deRSkYI8+eszMMswsFdgKbDOzL4/C+m8EHh+F5xERGVB9a5eOPApSsGMK851zTcC1wAvADHqPQBo2M0sArgZ+O8DXl5tZqZmV1tbWjmRVIjLOHRtTkMEFWwrxgfMSrgWedc51A26E6/4QsN45V32iLzrnHnLOlTjnSvLz80e4KhEZr5xz1Ld1a0whSMGWwoPAPiAVeMPMpgFNI1z3x9GuIxEJsaYOHz1+pzGFIAVVCs65HzjnCp1zV7he+4GLhrvSwNjEZcCq4T6HiEgwjk2GpzGF4AQ70JxpZvcf28dvZv9J71bDsDjnWp1zuc65xuE+h4hIMOo079GQBLv76OdAM3BD4KMJ+EWoQomIjJa+abO1pRCUYE9eO8U59w/9bv+bmW0MRSARkdFU3xaYDE9bCkEJdkuh3czOP3bDzM4D2kMTSURk9NTrWgpDEuyWwmeAX5lZZuB2PXBraCKJiIyeurYu4mONNE2GF5Rgp7nYBCwws4zA7WOT2G0OZTgRkZGqb9VkeEMxpCuvOeeaAmc2A9wdgjwiIqOqrrVL4wlDMJLLcap2RWTMa2jr1njCEIykFEY6zYWISMjVtWkyvKE46ZiCmTVz4l/+BiSHJJGIyCg6NqYgwTlpKTjn0sMVRERktPn9jvo2jSkMxUh2H4mIjGnNHT78TmczD4VKQUSi1rF5jzRtdvBUCiISteoCZzNrTCF4KgURiVp902arFIKmUhCRqFXfpmspDJVKQUSiVnVTB6BSGAqVgohEra2VTUzLTSFVk+EFTaUgIlFrS2UjpxdmDn5H6aNSEJGodKSlk8qGdhZMyfI6SkRRKYhIVNpS2XsJ+NOnaEthKFQKIhKVtlQ0YganTs7wOkpEUSmISFTaXNFIcV4q6Uk6m3koPCkFM8sys5VmtsPMtpvZ+7zIISLRa3NFg8YThsGr47QeAF50zn3UzBKAFI9yiEgUqm7qoKa5U+MJwxD2UjCzTOAC4DYA51wX0BXuHCISvTZX9A4yn6FSGDIvdh/NAGqBX5jZBjP7mZmlHn8nM1tuZqVmVlpbWxv+lCISsbZUNBBjMH+SSmGovCiFOOAs4H+dcwuBVuArx9/JOfeQc67EOVeSn58f7owiEsE2VzYye0I6yQmxXkeJOF6UQgVQ4ZxbG7i9kt6SEBEZMeccWyoatetomMJeCs65w8BBM5sTWHQJsC3cOUQkOlU1dnC0tYvTdeTRsHh19NFdwK8DRx7tAW73KIeIRJnNBxsAOENzHg2LJ6XgnNsIlHixbhGJbpsrG4mPNeZOSvc6SkTSGc0iElW2VDQyZ2I6iXEaZB4OlYKIRA3nHJsrGjhD4wnDplIQkahxsK6dpg6frqEwAioFEYkaZVW9ZzJrZtThUymISNQoq2oiNsaYPUGDzMOlUhCRqFFW1cisgjSS4jXIPFwqBRGJGmVVTcyfpF1HI6FSEJGoUNvcSU1zJ/M1njAiKgURiQrbDjUBcOpkHXk0EioFEYkKx4480pbCyKgURCQqlFU1MTUnmcxkXZN5JFQKIhIVtmmQeVSoFEQk4rV0+th7pFXjCaNApSAiEW9H3yCzthRGSqUgIhGvrEpHHo0WlYKIRLyyqkZyUxOYkJHodZSIp1IQkYhXVtXE/MkZmJnXUSKeSkFEIlqXz8+u6madnzBKVAoiEtHKa5rp7nEaTxglKgURiWjbqnTk0WhSKYhIRCuraiIlIZbpualeR4kKcV6s1Mz2Ac1AD+BzzpV4kUNEItvBujaeWl/BOdNziI3RIPNo8KQUAi5yzh3xcP0iEsG6e/zc9fgGcPDNa07zOk7U8LIURESG7fsv7WTjwQZ+/ImzKMpN8TpO1PBqTMEBL5vZOjNbfqI7mNlyMys1s9La2towxxORsezVnTU8+MYeblpcxJVnTPI6TlTxqhTOd86dBXwI+JyZXXD8HZxzDznnSpxzJfn5+eFPKCJjUk1TB/c8uYm5E9P5xlXzvY4TdTwpBedcZeDfGuBpYJEXOUQk8nz3hR20dPj40ScWkhQf63WcqBP2UjCzVDNLP/Y5cDmwNdw5RCTyrD9Qz6oNldyxdAYzC9K9jhOVvBhongA8HZijJA54zDn3ogc5RCSC+P2Of3u2jIL0RD530Uyv40StsJeCc24PsCDc6xWRyLZqQyWbKhq5/4YFpCbqwMlQ0RnNIjLmtXT6+PcXd3Dm1CyuPbPQ6zhRTaUgImPej1/dTW1zJ/d9eD4xOnM5pFQKIjKmVTa08/DqvVx3ViELi7K9jhP1VAoiMqb99x93gcE9l8/xOsq4oFIQkTGrvLqZp9ZX8Mkl0yjMSvY6zrigUhCRMev7L+8kJSGOz+oQ1LBRKYjImLThQD0vlVWz/IJiclITvI4zbqgURGTMcc7xHy/uJDc1gWXnz/A6zriiUhCRMef1XbWs2XOUuy6eqRPVwkylICJjyraqJr7wxEZm5KXy8cVFXscZd1QKIjJmlFc3c/PDa0lNiOVXn1pEYpxmQQ03lYKIjAl7alv4xM/WEhdj/PrOJUzN0dXUvKBSEBHPle6r4xM/XYvf73jszsXMyEv1OtK4pREcEfFMe1cP3395Jz//614mZybzi9sX6zoJHlMpiIgn1u2v454nN7HvaBu3LJnGvR+aS5qONPKc/gdEJOxe21nD8kfWMSEjkcfuXMy5p+R5HUkCoroUvrpqCw1tXfzvzWd7HSWsunx+EuI0XCRj06s7avj0I+uYNSGNR5ctJltnK48pUV0KsTHwxq5afD1+4mKj85dkQ1sXv157gHX766lqaKeqoZ2mDh+LZ+Sw/IJiLppToPnnZcx4ZXs1//joeuZMTOeRZYvISlEhjDVRXQqLZ+Ty6N8OUFbVxIKpWV7HGVXH5ph/4u0DtHX1MHdiOlOyk1k0I4fUxDh+t6GSZStKKc5P5ROLipg9IZ2inBQmZyXjd46qhnYqG9pp7vBx8dwCkuJ1PLiE1uryWj7z6DrmTcrgkU8tJjMl3utIcgLRXQrFOQCs3Xs04kqhqaObrZWN+P3gd44ev2PPkVa2VTVRVtVIeU0LBly9YDJ3XlDMvEkZ73r83ZfN5g9bDvHT1Xv41vPb+5bHGPjdu9c1LTeFb197OufP0n5dCY3DjR184YmNFOel8ciyxWQmqxDGqqguhYL0JIrzU1m7p47lF5wyKs/pnOOlsmomZyVxxpTQFM2LWw/z9We2cqSl8z1fy09P5NTJGVx+6kQ+ds7UAeeYj4+N4ZozC7l6wWSqmzo5UNfG/qOtHKxrIz42hsLsZAqzkmnt8vHN57Zz88Nr+YezpvC1K+eFZUbKpo5u/lhWzfNbDrGrupkYM2IMYmKMkmnZfPTsqZwzPRsz7fqKdL4eP59/fAMd3T38+KazVAhjnGelYGaxQClQ6Zy7KlTrWTwjl+c2VdHjd8SOcN96p6+Hrz29lZXrKgAomZbN7efN4AOnThiVMYujLZ3c92wZz20+xKmTM/iPj55OelI8MQZmxpTsZArSk4b0nGbGxMwkJmYmsWhGzgnvc+4pefz41d3872vv8Ocd1Xz1inlcf/aUYf1CPtTYzuryI+w90kpaYhwZyfFkJMXR6fNzpKWTI81d7D/ayuryI3T1+CnMSu775e93jvauHp7bfIgnSyuYnpvC1Qsmc0pBGlOykynMSqEgPVFjJBHmv/9Uzlv76vivjy1gZkGa13FkEF5uKXwB2A5kDHbHkVhSnMPjbx1g+6EmTivMHPbz1DR18OlH17HhQAN3XTyT7JQEfvnmPj732HoKs5K5/bzpfOycqaQn9f4V1Onr4Q9bDvHcpkMsLMri5iXTTjio1t3jZ+2eOl7edpjfb6qipdPHly6fzafffwrxYRocT4qP5Z7L53DVGZP52tNb+OeVm1lZWsG3PnIasyec/ESiLp+ftXuP8ucdNawuP8LumhYAYmOMnuP3UwGpCbFMyEjipiVFfHjBZBZOzXpP+bR2+nhh62F+W3qQH/x597u+lp+eyBWnTeTKMyZTMi1bBTHGvbGrlh+/tpuPlUzlIwuneB1HgmDOvfcHN+QrNZsCrAC+Ddw92JZCSUmJKy0tHda6Djd2sOQ7r/D1K+dxx9LiYT3HxoMNfPqRUprafdx/wwI+dPokAHr8jle2V/PwX/aydm8d6Ylx3LhoKskJcTy29gBHWjopSE+kprmT5PhYPnbOVK48YxJVDe2UV7ewq7qZNXuO0tzhIyk+hvfPzufuy+YwZ6J3Z3T6/Y6V6yr4fy9sp6XDx6XzJnDhnHzePyefSZnJtHb62FndzPZDTby5+yhv7KqludNHYlwMi4tzWTozj/Nn5TF3YjqdPj9NHd00tXeTGBdLXloiyQlDG9Bu7fRR2dBOZX07FfVt/HX3UV7dWUOnz09eWgJpiXF0dPvp8PXg9zvSk+JJS4wjLSmOWQVpXDA7n/NOydOgpgfWH6jnjhWl5Kcl8sznzhvy/72MnJmtc86VDOkxHpXCSuA7QDrwpVCWAsD7v/cqsyek89NPDum1wTnHr9bs51vPb6MgPYmffrKE+ZNPvGGzuaKBn63ey/NbDuF3jovnFHDbedM5f2YeO6ub+ekbe3l2UyXdPb2vd2yMMS03hbOKsvnAqRM5f2bemPqhqWvt4gevlPNS2WEONXYAvX+l1zb/fZyjID2RS+YVcMncCZwXxvwtnT7+vKOGV3fU0ON3JMXHkBQfiwGtXT20dPhobO8dqG/u9BFjcHphJtNyU5mUmcSEjCTOnpYdcQcfRJIn3z7I15/ZysTMJFZ8apHmMvJIRJSCmV0FXOGc+6yZXcgApWBmy4HlAEVFRWfv379/2Ou8d+VmXiw7zIZvXBb07oaWTh/3PrWZ5zcf4uK5Bdx/w4KgjqmuburA53cnHAA+3NjBpooGpuemMj0vJSKmBXbOUV7Twms7a9hxuJnivFTmTMzoOwR2LA8E+3r8bDzYwBvlR3hr71EONXZwqLGDLp8fM7jr4ll84ZJZJx1rOvbzEerv0zk3pl/LYHX3+PnWc9tYsWY/S2fl8cOPL9S5CB6KlFL4DnAL4AOS6B1TWOWcu3mgx4x0S2HV+grufnITf/j80gH/0u/vaEsn1z+4hn1HWvnSB+bwmQtO0b7rKOGc40hLF//+4g5WrqvgfcW5PHDjmeSmJbLxYD0vl1Xz9r46Gtq6aWzv/fD5HfGxRlxMDAlxMeSlJTA5K5mJGUlMyU5h9oQ0Zk9MZ3puKrExRkd3D/VtXbR0+EhJjCM9KY60hLh3vYc6fT2s21fP67tqeX1XLbtrWijKSeGUgjRmFqQxd2I6pxdmMj03dcy+95xzbK1sYvXuWt6paWXPkRbeqWmhqcPHnUtncO8H50btSaORIiJK4V0rP8mWQn8jLYXKhnbO++6fue/D87n9vMGv9/rN57bxi7/u5dE7NCdLNPtt6UG+8butpCTEEWPGkZZO4mKMhUVZFGQkkZkcT2ZyPPGxMfh6/HT3+On0+alt7qSqsYPDje3UNHdy7EcoIS6GGIOObv971mUGCbEx9Pgdvn4D8PGxxjnTczitMJODdW2U17Sw70hr333SE+M4rTCTO5bO4JJ5E8LyuvR3tKWTF8sOU17dQmZyPNkp8WQkx7O5opGXyw5TFdi1OCEjkeK8NIrzU7lwTgGXzQ9/Vnmv4ZRCVJ+ncExhVjJTspNZu6du0FKoburg0b/t57qzpqgQotz1JVNZMDWLbz63jczkeC6bP4EL5xQM6Tj69q4edte0sONwE+U1LTjnyEpJIDslgbSkONq7fDR3+Ghq76bT5ycu1oiNiSEuxjh1cgZLinPfcw3i7h4/5dUtbK1sZEtlI6vLa1m2opSL5uTzjavmU5wf2sM6Wzp9PLepiuc2H2LNnqP0+B2pCbG0dvX03ScxLoYLZufzT5fN5pJ5E8JybouEh6dbCsEa6ZYCwD1PbuLVnTWUfu1Sth1q4oFXytl+qInH7lhCUe7fr/D0f3+3lcfWHuDP91z4ruUiXunu8bPizX088KdyOnw9fPTsKcyZkM6U7BQKs5MpSE8kKyVhxOfhbD/UxKN/288zGypp7ephem4KV50xmSvPmMTcien0+B2N7d3Ut3UzOSuJlIRx8TdlRNOWwkksLs7hqfUV3PSztazZc5SMpDgcsGzF26z67LmkJ8VT2dDOE28d5PqSKSoEGTPiY2O4Y2kxV585me+9uJOnN1S+ZxeVGWQlx5OXlsj8yRmcOTWLBVOzKM5LJTEuloS4mBOWRnNHN89vPsSTpQdZf6CBxLgYrjpjMjctKXrPOSRxsUZuWiK5aYkh/57FO+NmS+FgXRsXfO9V0hLjuOP8Ym4/fzpbKxr55M/fYumsPH526zl8/ZmtrFx3kNe+fNGA00eIeM05x9HWLirr2zlY38bRli7qWruob+viUGMHmysaqG567xQpcTHGhIwkpmQnMzUnBV+Pn5fKqmnv7mFmQRo3njOVj549RUcLRZGIG2gO1miUAsDWykam5qS8a5/xo3/bz9ef2cpHFhby+01VfHxREd+89rQRr0vES4cbO9h4sJ7Kht5DcDt9PXR0+6lu6uBgXRsH69vo6PZzxemTuKFkCmee4MxyiXzafTSIE01zcfOSaZRXN7NizX4S4mL43EUzPUgmMromZibxwcxJXseQCDSuSmEg37hqfu81CSZlMDFzaBPOiYhEE5UCEBcbw/euX+B1DBERz+l0QxER6aNSEBGRPioFERHpo1IQEZE+KgUREemjUhARkT4qBRER6aNSEBGRPhEx95GZ1QINQGO/xZn9bp/o82P/5gFHhrHa/s8Z7NcHWzYWM59o+cluH5+1/7Lh5A5n5v6f6/0R3sww9t8f0fienuacyx9KeJxzEfEBPDTQ7RN93u/f0tFYXzBfH2zZWMw82Gs7WNaR5g5nZq9f60h8f4xW5kh4f4z39/Sxj0jaffT7k9w+0efH33+k6wvm64MtG4uZT7Q8mNd6oO9lqMKZuf/nen8E9/VIzHyi5XpPBykidh+NhJmVuiFOHeu1SMwMkZlbmcMnEnOPx8yRtKUwXA95HWAYIjEzRGZuZQ6fSMw97jJH/ZaCiIgEbzxsKYiISJBUCiIi0kelICIifcZ1KZjZUjP7iZn9zMze9DpPMMwsxsy+bWY/NLNbvc4TDDO70MxWB17rC/SqiggAAAXdSURBVL3OMxRmlmpmpWZ2lddZgmFm8wKv80oz+0ev8wTDzK41s5+a2W/M7HKv8wTLzIrN7GEzW+l1lpMJvIdXBF7jmwa7f8SWgpn93MxqzGzrccs/aGY7zWy3mX3lZM/hnFvtnPsM8BywIpR5A9lGnBm4BpgCdAMVocraL9toZHZAC5BEGDLDqOUGuBd4MjQp322U3tPbA+/pG4DzQpk3kG00Mj/jnLsT+AzwsVDm7ZdvNHLvcc4tC23SExti/uuAlYHX+OpBn3wkZ755+QFcAJwFbO23LBZ4BygGEoBNwHzgdHp/8ff/KOj3uCeB9EjIDHwF+HTgsSsjJHNM4HETgF9HyvsDuAy4EbgNuCoSMgceczXwAvCJSMkceNx/AmdFyvuj3+NC/nM4wvxfBc4M3OexwZ47jgjlnHvDzKYft3gRsNs5twfAzJ4ArnHOfQc44ea/mRUBjc655hDGBUYns5lVAF2Bmz2hS9trtF7ngHogMRQ5jzdKr/WFQCq9P1jtZvYH55x/LGcOPM+zwLNm9jzwWKjyBtY1Gq+zAd8FXnDOrQ9l3mNG+X0ddkPJT+/W+RRgI0HsHYrYUhhAIXCw3+0KYPEgj1kG/CJkiQY31MyrgB+a2VLgjVAGO4khZTaz64APAFnAj0Ib7aSGlNs59zUAM7sNOBLKQjiJob7WF9K7uyAR+ENIkw1sqO/pu4BLgUwzm+mc+0kow53EUF/rXODbwEIz+2qgPLw0UP4fAD8ysysJYiqMaCuFIXPO3ed1hqFwzrXRW2QRwzm3it4yi0jOuV96nSFYzrnXgNc8jjEkzrkf0PuLK6I4547SOw4ypjnnWoHbg71/xA40D6ASmNrv9pTAsrFMmcMnEnMrc/hEau5jRiV/tJXC28AsM5thZgn0DhI+63GmwShz+ERibmUOn0jNfczo5A/3qPkojr4/Dhzi74dmLgssvwLYRe8o/Ne8zqnMyq3MYytzJOcOR35NiCciIn2ibfeRiIiMgEpBRET6qBRERKSPSkFERPqoFEREpI9KQURE+qgUJCKZWUuY1zcq19uw3mtLNJrZRjPbYWbfD+Ix15rZ/NFYv8hgVAoigJmddB4w59y5o7i61c65M4GFwFVmNth1D66ld6ZWkZBTKUjUMLNTzOxFM1tnvVd6mxtY/mEzW2tmG8zsT2Y2IbD8X83sETP7K/BI4PbPzew1M9tjZp/v99wtgX8vDHx9ZeAv/V8Hpn7GzK4ILFtnZj8ws+dOltc5107vdMaFgcffaWZvm9kmM3vKzFLM7Fx6r4/wvcDWxSkDfZ8io0GlINHkIeAu59zZwJeA/wks/wuwxDm3EHgC+Od+j5kPXOqc+3jg9lx6p/leBNxnZvEnWM9C4IuBxxYD55lZEvAg8KHA+vMHC2tm2cAs/j4F+irn3DnOuQXAdnqnLniT3vlrvuycO9M5985Jvk+RERv3U2dLdDCzNOBc4LeBP9zh7xf0mQL8xswm0XtFqr39Hvps4C/2Y553znUCnWZWQ+/V4o6/hOhbzrmKwHo3AtPpvdzoHufcsed+HFg+QNylZraJ3kL4b+fc4cDy08zsW/RedyINeGmI36fIiKkUJFrEAA2BffXH+yFwv3Pu2cBFaP6139daj7tvZ7/Pezjxz0gw9zmZ1c65q8xsBvA3M3vSObcR+CVwrXNuU+DCPhee4LEn+z5FRky7jyQqOOeagL1mdj30XuLRzBYEvpzJ3+eVvzVEEXYCxf0ukTjoBegDWxXfBe4NLEoHDgV2Wd3U767Nga8N9n2KjJhKQSJViplV9Pu4m95fpMsCu2bK6L0+LfRuGfzWzNYBR0IRJrAL6rPAi4H1NAONQTz0J8AFgTL5BrAW+Cuwo999ngC+HBgoP4WBv0+REdPU2SKjxMzSnHMtgaORfgyUO+f+y+tcIkOhLQWR0XNnYOC5jN5dVg96nEdkyLSlICIifbSlICIifVQKIiLSR6UgIiJ9VAoiItJHpSAiIn1UCiIi0uf/A0Rb5hU/GloBAAAAAElFTkSuQmCC
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's also not a bad idea to run a batch through your model and make sure the shape of what goes in, and comes out, looks right.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">preds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(3,
 tensor(4.9295, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;),
 torch.Size([2, 68, 50264]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">3e-5</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">fit_cbs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>rouge1</th>
      <th>rouge2</th>
      <th>rougeL</th>
      <th>bertscore_precision</th>
      <th>bertscore_recall</th>
      <th>bertscore_f1</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.759184</td>
      <td>1.707277</td>
      <td>0.377308</td>
      <td>0.157118</td>
      <td>0.254392</td>
      <td>0.876762</td>
      <td>0.891991</td>
      <td>0.884229</td>
      <td>14:03</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And now we can look at the generated predictions using our <code>text_gen_kwargs</code> above</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>London (CNN) -- As tens of thousands of athletes, team officials and visitors gather in London ahead of the Olympic opening ceremony on Friday, security is paramount for the Games organizers and British authorities. And perhaps the biggest headache of all is the challenge of safeguarding the more than 100 heads of state and foreign dignitaries who will attend the opening ceremony at the Olympic Park -- Queen Elizabeth II, first lady Michelle Obama and U.S. presidential hopeful Mitt Romney among them. But should visitors and competitors be worried? Security concerns hit the headlines this month when it emerged that private security contractor G4S, which was supposed to have provided 10,400 guards for the Olympics and Paralympics, would not be able to deliver. As a result, the government is deploying 18,200 troops -- many more than planned and almost twice as many as are in Afghanistan -- in order to remedy the shortfall. About 1,200 of those were called up just this week after being placed on standby. Nonetheless, Culture Secretary Jeremy Hunt, the minister responsible for the Games, said Tuesday that the government "continues to have every confidence that we will deliver a safe and secure Games." The decision to call up the extra troops was down to ministers' determination to "leave nothing to chance</td>
      <td>The government is deploying 18,200 troops to make up for a shortfall in security guards.\nOne headache is safeguarding more than 100 visiting heads of state and foreign dignitaries.\nPrivate security contractor G4S has failed to recruit and accredit enough security staff.\nFighter jets are on standby, and a helicopter carrier is moored in the Thames.</td>
      <td>Security concerns hit the headlines this month when it emerged that security contractor G4S would not be able to deliver .\nThe government is deploying 18,200 troops -- many more than planned and almost twice as many as are in Afghanistan .\nMore than 100 heads of state and foreign dignitaries will attend the opening ceremony at the Olympic Park .</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Washington (CNN) -- In one ill-fated fundraiser, Mitt Romney managed to offend Palestinians, Latinos and some of the same people he's counting on for support if he wants to unseat President Barack Obama. It isn't the first time Romney's oratory fumbles have put his campaign on its heels, handed opponents material to push the stereotype of him as an out-of-touch businessman and provoked members of the party's conservative base to question his worthiness as their standard-bearer. "Everybody has the same reaction: 'dumb, dumb, dumb,'" said Larry Sabato, director of the University of Virginia's Center for Politics, adding that Romney's gaffes reinforce a sitcom-like caricature of the candidate. Opinion: What's wrong with Romney. After the tape, recorded during a May 17 private fundraiser at the home of Sun Capital executive Marc Leder, made the rounds on Monday, Romney convened a hastily scheduled news conference Monday night in which he said his comments were "off the cuff" and "not elegantly stated." However, he defended the main message of his remarks, saying he that while he could have made them "more clearly," he said he was trying to point out the differences between his and Obama's campaigns.</td>
      <td>GOP presidential candidate Mitt Romney's verbal gaffes have once again stymied his campaign's ability to control the narrative.\nDemocrats were gleeful, while Republicans left scrambling after Romney's comments.\nLess than two months before the election, Romney's challenge is to steer clear of speaking slip ups; hammer Obama on the economy.</td>
      <td>Romney's gaffes reinforce a sitcom-like caricature of the candidate, professor says .\nHe says he was trying to point out the differences between his and President Obama's campaigns .\nThe gaffe came during a May 17 fundraiser at the home of Sun Capital executive Marc Leder .\nAfter the tape made the rounds on Monday, Romney convened a hastily scheduled news conference .</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Even better though, blurr augments the fastai Learner with a <code>blurr_summarize</code> method that allows you to use huggingface's <code>PreTrainedModel.generate</code> method to create something more human-like.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_article</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">The past 12 months have been the worst for aviation fatalities so far this decade - with the total of number of people killed if airline </span>
<span class="s2">crashes reaching 1,050 even before the Air Asia plane vanished. Two incidents involving Malaysia Airlines planes - one over eastern Ukraine and the other in the Indian Ocean - led to the deaths of 537 people, while an Air Algerie crash in Mali killed 116 and TransAsia Airways crash in Taiwan killed a further 49 people. The remaining 456 fatalities were largely in incidents involving small commercial planes or private aircraft operating on behalf of companies, governments or organisations. Despite 2014 having the highest number of fatalities so far this decade, the total number of crashes was in fact the lowest since the first commercial jet airliner took off in 1949 - totalling just 111 across the whole world over the past 12 months. The all-time deadliest year for aviation was 1972 when a staggering 2,429 people were killed in a total of 55 plane crashes - including the crash of Aeroflot Flight 217, which killed 174 people in Russia, and Convair 990 Coronado, which claimed 155 lives in Spain. However this year&#39;s total death count of 1,212, including those presumed dead on board the missing Air Asia flight, marks a significant rise on the very low 265 fatalities in 2013 - which led to it being named the safest year in aviation since the end of the Second World War. Scroll down for videos. Deadly: The past 12 months have been the worst for aviation fatalities so far this decade - with the total of number of people killed if airline crashes reaching 1,158 even before the Air Asia plane (pictured) vanished. Fatal: Two incidents involving Malaysia Airlines planes - one over eastern Ukraine (pictured) and the other in the Indian Ocean - led to the deaths of 537 people. Surprising: Despite 2014 having the highest number of fatalities so far this decade, the total number of crashes was in fact the lowest since the first commercial jet airliner took off in 1949. 2014 has been a horrific year for Malaysia-based airlines, with 537 people dying on Malaysia Airlines planes, and a further 162 people missing and feared dead in this week&#39;s Air Asia incident. In total more than half the people killed in aviation incidents this year had been flying on board Malaysia-registered planes. In January a total of 12 people lost their lives in five separate incidents, while the same number of crashes in February killed 107. </span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can override the <code>text_gen_kwargs</code> we specified for our <code>DataLoaders</code> when we generate text using blurr's <code>Learner.blurr_generate</code> method</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">outputs</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">blurr_generate</span><span class="p">(</span><span class="n">test_article</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=== Prediction </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1"> ===</span><span class="se">\n</span><span class="si">{</span><span class="n">o</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>=== Prediction 1 ===
 2014 has been the worst year for aviation fatalities so far this decade so far .
The total number of people killed if airline crashes reached 1,158 even before Air Asia plane vanished .
Two incidents involving Malaysia Airlines planes led to the deaths of 537 people in the past 12 months .
Despite 2014 having the highest number of fatalities, the number of crashes was in fact the lowest since first commercial jet airliner took off in 1949 - totalling just 111 across the whole world .

=== Prediction 2 ===
 2014 has been the worst year for aviation fatalities so far this decade so far .
The total number of people killed if airline crashes reached 1,158 even before Air Asia plane vanished .
Two incidents involving Malaysia Airlines planes led to the deaths of 537 people in the past 12 months .
Despite 2014 having the highest number of fatalities, the number of crashes was in fact the lowest since first commercial jet airliner took off in 1949 - totalling just 111 across the whole world.

=== Prediction 3 ===
 2014 has been the worst year for aviation fatalities so far this decade so far .
The total number of people killed if airline crashes reached 1,158 even before Air Asia plane vanished .
Two incidents involving Malaysia Airlines planes led to the deaths of 537 people in the past 12 months .
Despite 2014 having the highest number of fatalities, the number of crashes was in fact the lowest since first commercial jet airliner took off in 1949 .

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>What about inference?  Easy!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">&#39;ft_cnndm_export.pkl&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inf_learn</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">&#39;ft_cnndm_export.pkl&#39;</span><span class="p">)</span>
<span class="n">inf_learn</span><span class="o">.</span><span class="n">blurr_generate</span><span class="p">(</span><span class="n">test_article</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39; 2014 has been the worst year for aviation fatalities so far this decade so far .\nThe total number of people killed if airline crashes reached 1,158 even before Air Asia plane vanished .\nTwo incidents involving Malaysia Airlines planes led to the deaths of 537 people in the past 12 months .\nDespite 2014 having the highest number of fatalities, the number of crashes was in fact the lowest since first commercial jet airliner took off in 1949 - totalling just 111 across the whole world .&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="That's-it">That's it<a class="anchor-link" href="#That's-it"> </a></h2><p><a href="https://ohmeow.github.io/blurr/">blurr</a> supports a number of huggingface transformer model tasks in addition to summarization (e.g., sequence classification , token classification, and question/answering, causal language modeling, and transation). The docs include examples for each of these tasks if you're curious to learn more.</p>
<p>For more information about ohmeow or to get in contact with me, head over to <a href="ohmeow.com">ohmeow.com</a> for all the details.</p>
<p>Thanks!</p>

</div>
</div>
</div>
</div>

<script type="application/vnd.jupyter.widget-state+json">
{"f955be89447249159d6493c04c0ae578": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_view_name": "HBoxView", "_dom_classes": [], "_model_name": "HBoxModel", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.5.0", "box_style": "", "layout": "IPY_MODEL_8771e20050b14225af4d2188652b697f", "_model_module": "@jupyter-widgets/controls", "children": ["IPY_MODEL_62906b03982d49f287b4599be6df7e40", "IPY_MODEL_495844eb7a284f779f005bd204dff8c2"]}}, "8771e20050b14225af4d2188652b697f": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}, "62906b03982d49f287b4599be6df7e40": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_view_name": "ProgressView", "style": "IPY_MODEL_c5e2a4438b23434e8e9f075fe1187761", "_dom_classes": [], "description": "Downloading: 100%", "_model_name": "FloatProgressModel", "bar_style": "success", "max": 482, "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": 482, "_view_count": null, "_view_module_version": "1.5.0", "orientation": "horizontal", "min": 0, "description_tooltip": null, "_model_module": "@jupyter-widgets/controls", "layout": "IPY_MODEL_ffafcf7f5eb148d4a09f04722f8947bf"}}, "495844eb7a284f779f005bd204dff8c2": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_view_name": "HTMLView", "style": "IPY_MODEL_1a054f0b956c49439cd1e5da5b861425", "_dom_classes": [], "description": "", "_model_name": "HTMLModel", "placeholder": "\u200b", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": " 482/482 [00:00&lt;00:00, 3.47kB/s]", "_view_count": null, "_view_module_version": "1.5.0", "description_tooltip": null, "_model_module": "@jupyter-widgets/controls", "layout": "IPY_MODEL_97dfe1a30d6a40e2bc6643eb1ab31c2e"}}, "c5e2a4438b23434e8e9f075fe1187761": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_view_name": "StyleView", "_model_name": "ProgressStyleModel", "description_width": "initial", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "bar_color": null, "_model_module": "@jupyter-widgets/controls"}}, "ffafcf7f5eb148d4a09f04722f8947bf": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}, "1a054f0b956c49439cd1e5da5b861425": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_view_name": "StyleView", "_model_name": "DescriptionStyleModel", "description_width": "", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "_model_module": "@jupyter-widgets/controls"}}, "97dfe1a30d6a40e2bc6643eb1ab31c2e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}, "fd7869ea2bd54cbd816b7b487584d371": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_view_name": "HBoxView", "_dom_classes": [], "_model_name": "HBoxModel", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.5.0", "box_style": "", "layout": "IPY_MODEL_e7140c425a6840eca3088a4c74ced844", "_model_module": "@jupyter-widgets/controls", "children": ["IPY_MODEL_2a40757d5b3f42df8d10896051de88bd", "IPY_MODEL_d8a48aa73da4459783374622cf9f98d6"]}}, "e7140c425a6840eca3088a4c74ced844": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}, "2a40757d5b3f42df8d10896051de88bd": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_view_name": "ProgressView", "style": "IPY_MODEL_c26f10b0de464b12b0606bdde9765746", "_dom_classes": [], "description": "Downloading: 100%", "_model_name": "FloatProgressModel", "bar_style": "success", "max": 1425941629, "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": 1425941629, "_view_count": null, "_view_module_version": "1.5.0", "orientation": "horizontal", "min": 0, "description_tooltip": null, "_model_module": "@jupyter-widgets/controls", "layout": "IPY_MODEL_07a033417e024aa6960bebc83bb50332"}}, "d8a48aa73da4459783374622cf9f98d6": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_view_name": "HTMLView", "style": "IPY_MODEL_983bd441e1e24210ad272b3fb087cd68", "_dom_classes": [], "description": "", "_model_name": "HTMLModel", "placeholder": "\u200b", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": " 1.43G/1.43G [00:36&lt;00:00, 39.1MB/s]", "_view_count": null, "_view_module_version": "1.5.0", "description_tooltip": null, "_model_module": "@jupyter-widgets/controls", "layout": "IPY_MODEL_49ed6f69e82a492eb136b80ae8baf007"}}, "c26f10b0de464b12b0606bdde9765746": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_view_name": "StyleView", "_model_name": "ProgressStyleModel", "description_width": "initial", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "bar_color": null, "_model_module": "@jupyter-widgets/controls"}}, "07a033417e024aa6960bebc83bb50332": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}, "983bd441e1e24210ad272b3fb087cd68": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_view_name": "StyleView", "_model_name": "DescriptionStyleModel", "description_width": "", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "_model_module": "@jupyter-widgets/controls"}}, "49ed6f69e82a492eb136b80ae8baf007": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}}
</script>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="ohmeow/ohmeow_website"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/posts/2020/05/23/text-generation-with-blurr.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p>A full-stack web application and ML development company.</p>
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a class="fa-icon" rel="me" href="mailto:wgilliam@ohmeow.com" title="wgilliam@ohmeow.com"><i class="far fa-envelope"></i></a></li><li><a rel="me" href="https://github.com/ohmeow" title="ohmeow"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/waydegilliam" title="waydegilliam"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul></div>

  </div>

</footer></body>

</html>
