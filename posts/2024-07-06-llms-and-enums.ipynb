{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Structuring Enums for Flawless LLM results with Instructor\"\n",
    "image: images/blog-20240706/header.png\n",
    "author: Wayde Gilliam\n",
    "date: \"2024-07-06\"\n",
    "description: Enums enhance code readability and maintainability by replacing hard-coded constants with\n",
    "  meaningful names and restricting variables to predefined values that can be used across all tiers of your application.\n",
    "  This reduces bugs and improves code clarity, making it easier to refactor and understand. However, it can be frustrating\n",
    "  to get LLMs and libraries like Instructor to use them correctly when dealing with structured output.\n",
    "\n",
    "categories:\n",
    "  - LLMs\n",
    "  - pydantic\n",
    "  - Instructor\n",
    "\n",
    "toc: true\n",
    "hide: false\n",
    "search: true\n",
    "\n",
    "output-file: 2024-07-06-llms-and-enums.html\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructor Best Practices and Cautions\n",
    "\n",
    "<div>\n",
    "\n",
    "I'm spending some time with the <a href=\"https://x.com/jxnlco\" target=\"_blank\">Jason Liu</a>'s <a href=\"https://useinstructor.com/\" target=\"_blank\">Instructor library</a> in building a function calling solution that returns structured output because, well, Hamel recommends it for proprietary models.\n",
    "\n",
    "> <img src=\"images/blog-20240603/hamel-icon.png\" alt=\"Hamel\" style=\"border-radius:30px;width:auto;height:25px;\"> For open models you should use outlines. for closed models APIs you should use instructor.\n",
    "\n",
    "The library is intuitive, fun to use, and has some really nice documentation. When it comes to choosing whether to use enums or literals in your pydantic classes, <a href=\"https://python.useinstructor.com/tutorials/2-tips/?h=enums\" target=\"_blank\">the docs recommend the following</a>:\n",
    "\n",
    "> For classification we've found theres generally two methods of modeling.\n",
    ">\n",
    "> 1. using Enums\n",
    "> 2. using Literals\n",
    ">\n",
    "> Use an enum in Python when you need a set of named constants that are related and you want to ensure type safety, readability, and prevent\n",
    "> invalid values. Enums are helpful for grouping and iterating over these constants.\n",
    ">\n",
    "> Use literals when you have a small, unchanging set of values that you don't need to group or iterate over, and when type safety and\n",
    "> preventing invalid values is less of a concern. Literals are simpler and more direct for basic, one-off values.\n",
    "\n",
    "... and they also seems to indicate that <a href=\"https://python.useinstructor.com/concepts/prompting/?h=enums#tips-for-enumerations\" target=\"_blank\">getting them to work as expected might be challenging</a> ...\n",
    "\n",
    "> If you're having a hard time with Enum an alternative is to use Literal\n",
    "\n",
    "I found this out first-hand when I was attempting to define an enum for a number of named entities I wanted an LLM to identifiy in a given document. My intial code worked pretty nicely with GPT-4o but failed miserabley time and time again with every Antrhopic model I tried (I'll explain why below). If you're looking for the TL;DR, the final version of my code at the end of this post represents a substantially more resiliant solution that works across vendors (I also tested this with <a href=\"https://fireworks.ai/\" target=\"_blank\">Fireworks</a>), offering a better guaranttee your LLM calls find the entities you care about correctly.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v0: Using `Enum`\n",
    "\n",
    "This is the initial `Enum` and pydantic classes I started with. It works pretty damn well with OpenAI's GPT-4o but fails spectacularly when using any of the Anthopic models.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```python\n",
    "class EntityGroup(str, Enum):\n",
    "    \"\"\"A named entity type.\"\"\"\n",
    "\n",
    "    PERSON = \"PERSON\"\n",
    "    ORGANIZATION = \"ORGANIZATION\"\n",
    "    LOCATION = \"LOCATION\"\n",
    "    DATE = \"DATE\"\n",
    "    TIME = \"TIME\"\n",
    "    PERCENT = \"PERCENT\"\n",
    "    MONEY = \"MONEY\"\n",
    "    QUANTITY = \"QUANTITY\"\n",
    "    ORDINAL = \"ORDINAL\"\n",
    "    CARDINAL = \"CARDINAL\"\n",
    "    EMAIL = \"EMAIL\"\n",
    "    PHONE_NUMBER = \"PHONE_NUMBER\"\n",
    "    CREDIT_CARD_NUMBER = \"CREDIT_CARD_NUMBER\"\n",
    "    SSN = \"SSN\"\n",
    "\n",
    "\n",
    "class NamedEntity(BaseModel):\n",
    "    entity_group: EntityGroup\n",
    "    word: str\n",
    "\n",
    "\n",
    "class DocumentNER(BaseModel):\n",
    "    named_entities: list[NamedEntity]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "When using the Anthropic models, I would consistently see it trying to set `entity_group` to a string rather than a proper enum value from the `EntityGroup` enum.\n",
    "\n",
    "After iterating through a number of prompt and class/field description modifications, I decided to give up and replace my `Enum` with a `Literal`. And guess what, everything worked great across all model vendors.\n",
    "\n",
    "I also decided to lookup the named entities used in Spacy and use those names in my `Enum` as it makes sense to me that perhaps these libraries might have been included in the training of these LLMs and so maybe will help it do a better job of finding the entities I care about.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v1: Using `Literal`\n",
    "\n",
    "Using the `Literal` type fixed everything and works great across all models! Here's what it looks like:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```python\n",
    "class NamedEntity(BaseModel):\n",
    "    \"\"\"A named entity found in a document.\"\"\"\n",
    "\n",
    "    entity_type: Literal[\n",
    "        \"PERSON\",\n",
    "        \"NORP\",\n",
    "        \"FAC\",\n",
    "        \"ORG\",\n",
    "        \"GPE\",\n",
    "        \"LOC\",\n",
    "        \"PRODUCT\",\n",
    "        \"EVENT\",\n",
    "        \"WORK_OF_ART\",\n",
    "        \"LAW\",\n",
    "        \"LANGUAGE\",\n",
    "        \"DATE\",\n",
    "        \"TIME\",\n",
    "        \"PERCENT\",\n",
    "        \"MONEY\",\n",
    "        \"QUANTITY\",\n",
    "        \"ORDINAL\",\n",
    "        \"CARDINAL\",\n",
    "        \"OTHER\",\n",
    "    ]\n",
    "    entity: str\n",
    "\n",
    "\n",
    "class DocumentNERTask(BaseModel):\n",
    "    named_entities: list[NamedEntity]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works great ... but I really wanted to use an `Enum` for the reasons listed at the top of this post. And as I'm the kinda guy who enjoys fighting with CUDA installs on his local DL rig, I decided to give it a go after taking a few hours off to enjoy the Euros and Copa America tourneys (also Germany should have won; that was a handball but nah, I'm not angry, nope, not bent at all).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2: Using `Enum` Revisted\n",
    "\n",
    "Here's the TL;DR version of the code. This version is working fabulously across all APIs and I have yet to encounter a single exception involving Instructor being unable to assign a valid value from the `Enum`.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```python\n",
    "class NamedEntityType(str, Enum):\n",
    "    \"\"\"Valid types of named entities to extract.\"\"\"\n",
    "\n",
    "    PERSON = \"PERSON\"\n",
    "    NORP = \"NORP\"\n",
    "    FAC = \"FAC\"\n",
    "    ORG = \"ORG\"\n",
    "    GPE = \"GPE\"\n",
    "    LOC = \"LOC\"\n",
    "    PRODUCT = \"PRODUCT\"\n",
    "    EVENT = \"EVENT\"\n",
    "    WORK_OF_ART = \"WORK_OF_ART\"\n",
    "    LAW = \"LAW\"\n",
    "    LANGUAGE = \"LANGUAGE\"\n",
    "    DATE = \"DATE\"\n",
    "    TIME = \"TIME\"\n",
    "    PERCENT = \"PERCENT\"\n",
    "    MONEY = \"MONEY\"\n",
    "    QUANTITY = \"QUANTITY\"\n",
    "    ORDINAL = \"ORDINAL\"\n",
    "    CARDINAL = \"CARDINAL\"\n",
    "    OTHER = \"OTHER\"\n",
    "\n",
    "\n",
    "class NamedEntity(BaseModel):\n",
    "    \"\"\"A named entity result.\"\"\"\n",
    "\n",
    "    def convert_str_to_named_entity_type(v: str | NamedEntityType) -> NamedEntityType:\n",
    "        \"\"\"Ensure entity type is a valid enum.\"\"\"\n",
    "        if isinstance(v, NamedEntityType):\n",
    "            return v\n",
    "        else:\n",
    "            try:\n",
    "                return NamedEntityType(v)\n",
    "            except ValueError:\n",
    "                return NamedEntityType.OTHER\n",
    "\n",
    "    entity_type: Annotated[str, BeforeValidator(convert_str_to_named_entity_type)]\n",
    "    entity_mention: str = Field(..., description=\"The named entity recognized.\")\n",
    "\n",
    "\n",
    "class DocumentNERTask(BaseModel):\n",
    "    named_entities: list[NamedEntity]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the return of the `Enum`, the most noticeable change involves the inclusion of a `BeforeValidator` that ensures the value is assigned to a valid enum as defined in `NamedEntity`. In cases where it wants to add an entity to the list of `named_entities` that isn't defined in the `NamedEntityType` enum or is named differently (e.g., \"ORGANIZATION\" vs. \"ORG\"), it will assign them to `OTHER`.\n",
    "\n",
    "With this in place, I now have a solution that is:\n",
    "\n",
    "1. More resiliant\n",
    "\n",
    "2. Can be used in debugging named entity recogintion (e.g, I can explore what named entities might be missing from the `Enum` or getting named differently by looking at those that get associated with the `OTHER` value)\n",
    "\n",
    "3. I can use that same beautiful `Enum` across all parts of my application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2.0.1: Using `Enum` and `fuzzywuzzy`\n",
    "\n",
    "A suggestion from a Twitter user inspired me to enhance our approach by implementing similarity-based matching rather than relying on exact matches. To make it so, I installed the `fuzzywuzzy` library and made the necessary modifications to increase the likelihood of delivering high-quality results.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```python\n",
    "class NamedEntityType(str, Enum):\n",
    "    \"\"\"Valid types of named entities to extract.\"\"\"\n",
    "\n",
    "    PERSON = \"PERSON\"\n",
    "    NORP = \"NORP\"\n",
    "    FAC = \"FAC\"\n",
    "    ORG = \"ORG\"\n",
    "    GPE = \"GPE\"\n",
    "    LOC = \"LOC\"\n",
    "    PRODUCT = \"PRODUCT\"\n",
    "    EVENT = \"EVENT\"\n",
    "    WORK_OF_ART = \"WORK_OF_ART\"\n",
    "    LAW = \"LAW\"\n",
    "    LANGUAGE = \"LANGUAGE\"\n",
    "    DATE = \"DATE\"\n",
    "    TIME = \"TIME\"\n",
    "    PERCENT = \"PERCENT\"\n",
    "    MONEY = \"MONEY\"\n",
    "    QUANTITY = \"QUANTITY\"\n",
    "    ORDINAL = \"ORDINAL\"\n",
    "    CARDINAL = \"CARDINAL\"\n",
    "    OTHER = \"OTHER\"\n",
    "\n",
    "\n",
    "class NamedEntity(BaseModel):\n",
    "    \"\"\"A named entity result.\"\"\"\n",
    "\n",
    "    def convert_str_to_named_entity_type(v: str | NamedEntityType) -> NamedEntityType:\n",
    "        \"\"\"Ensure entity type is a valid enum.\"\"\"\n",
    "        if isinstance(v, NamedEntityType):\n",
    "            return v\n",
    "        else:\n",
    "            try:\n",
    "                match, score = fuzzy_process.extractOne(v.upper(), [e.value for e in list(NamedEntityType)])\n",
    "                return NamedEntityType(match) if score >= 60 else NamedEntityType.OTHER\n",
    "            except ValueError:\n",
    "                return NamedEntityType.OTHER\n",
    "\n",
    "    entity_type: Annotated[str, BeforeValidator(convert_str_to_named_entity_type)]\n",
    "    entity_mention: str = Field(..., description=\"The named entity recognized.\")\n",
    "\n",
    "\n",
    "class DocumentNERTask(BaseModel):\n",
    "    named_entities: list[NamedEntity]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This improves those cases where, for example, the LLM wants to define the entity type as \"ORGANIZATION\" but it is defined in the `Enum` as \"ORG\".\n",
    "\n",
    "Another option potentially worth exploring is to use the `llm_validator` function to make a call out to the LLM when exceptions happen and prompt it to coerce the value into something in the `Enum`. This could hike up your costs a bit but I imagine using a cheap model like GPT-3.5-Turbo could do the job just fine, and would likely you give an addtional robustness in quality results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "That's it.\n",
    "\n",
    "If you found this helpful and/or have suggestions on how to improve the use of `Enum`s in Instructor, lmk in the comments below or on <a href=\"https://x.com/waydegilliam\" target=\"_blank\">X</a>. Until then, time to enjoy some football and see if Brazil can make it into the semis.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2022-04-12-ajtfb-chapter-9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ohmeow_website')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "9eb9bda8f49c57e6addc88daf9eb4f6c227a77e767b644e5d20488a497d532a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
