{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'A Journey Through Fastbook (AJTFB) - Chapter 8: Collaborative Filtering'\n",
    "image: images/fastbook.jpg\n",
    "author: Wayde Gilliam\n",
    "date: '2022-03-31'\n",
    "description: This chapter of [\"Deep Learning for Coders with fastai & PyTorch\"](https://github.com/fastai/fastbook) moves us away \n",
    "  from computer vision to collaborative filtering (think recommendation systems). We'll explore building these models using the \n",
    "  traditional \"dot product\" approach and also using a neural network, but we'll begin by covering the idea of \"latent factors,\" which are \n",
    "  both important for colloborative and tabular models.  Lets go!\n",
    "\n",
    "categories:\n",
    "- fastai\n",
    "- fastbook\n",
    "- collaborative filtering\n",
    "- latent factors\n",
    "- embeddings\n",
    "- recommender systems\n",
    "- recsys\n",
    "\n",
    "toc: true\n",
    "hide: false\n",
    "search: true\n",
    "\n",
    "output-file: 2022-03-31-ajtfb-chapter-8.html\n",
    "aliases:\n",
    "- /collaborative filtering/embeddings/fastai/fastbook/latent factors/recommender systems/recsys/2022/03/31/ajtfb-chapter-8\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfcRNESotGLU"
   },
   "source": [
    "Other posts in this series:  \n",
    "[A Journey Through Fastbook (AJTFB) - Chapter 1](2020-11-06-ajtfb-chapter-1.ipynb)  \n",
    "[A Journey Through Fastbook (AJTFB) - Chapter 2](2020-11-16-ajtfb-chapter-2.ipynb)  \n",
    "[A Journey Through Fastbook (AJTFB) - Chapter 3](2020-11-22-ajtfb-chapter-3.ipynb)  \n",
    "[A Journey Through Fastbook (AJTFB) - Chapter 4](2021-05-23-ajtfb-chapter-4.ipynb)  \n",
    "[A Journey Through Fastbook (AJTFB) - Chapter 5](2021-06-03-ajtfb-chapter-5.ipynb)  \n",
    "[A Journey Through Fastbook (AJTFB) - Chapter 6a](2021-06-10-ajtfb-chapter-6-multilabel.ipynb)  \n",
    "[A Journey Through Fastbook (AJTFB) - Chapter 6b](2022-02-09-ajtfb-chapter-6-regression.ipynb)  \n",
    "[A Journey Through Fastbook (AJTFB) - Chapter 7](2022-03-28-ajtfb-chapter-7.ipynb)  \n",
    "[A Journey Through Fastbook (AJTFB) - Chapter 9](2022-04-25-ajtfb-chapter-9.ipynb)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWxCOulE-ACJ",
    "outputId": "e8ce4cf1-124e-4f82-89e1-dc286fe6900e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 188 kB 5.3 MB/s \n",
      "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "! pip install fastai -Uqq\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lGlBrkfiY71Q"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "def plot_function(f, tx=None, ty=None, title=None, min=-2, max=2, figsize=(6,4)):\n",
    "    x = torch.linspace(min,max)\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot(x,f(x))\n",
    "    if tx is not None: ax.set_xlabel(tx)\n",
    "    if ty is not None: ax.set_ylabel(ty)\n",
    "    if title is not None: ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYAYlO8GPs7r"
   },
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "**What is it?**\n",
    "\n",
    "Think recommender systems which \"look at which products the current user has used or liked, find other users who have used or liked similar products, and then recommend other products that those users have used or liked.\"\n",
    "\n",
    "The key to making collaborative filtering and tabular models, is the idea of **latent factors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEEuv8IvQYRv"
   },
   "source": [
    "## What are \"latent factors\" and what is the problem they solve?\n",
    "\n",
    "Remember that models can only work with numbers, and while something like \"price\" can be used to accurately reflect the value of a house, how do we represent numerically concepts like the day of week, the make/model of a car, or the job function of an employee?\n",
    "\n",
    "The answer is with latent factors.\n",
    "\n",
    "In a nutshell, latent factors are numbers associated to a thing (e.g., day of week, model of car, job function, etc...) that are **learnt** during model training. At the end this process, we have numbers that provide a representation of the thing we can use and explore in a variety of ways.  These factors are called \"latent\" because we don't know what they are beforehand.\n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "The learnt numbers for \"a thing\" may vary to one degree or another based on the data used during training and your objective.  For example, what \"Sunday\" means may be represented differently when you are trying to forecast how many bottle of scotch will be sold that day than if you were trying to predict the number of options that will be traded for a certain equity.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{.callout-important}\n",
    "\n",
    "Latent factors allows us to learn a numerical representation of a thing (especially those for which a single number would not do it justice)\n",
    "\n",
    ":::\n",
    "\n",
    "If we had something like this ...\n",
    "\n",
    "![](https://raw.githubusercontent.com/fastai/fastbook/035016fb0cc826542aef77864f36df88a5055d06/images/att_00040.png)\n",
    "\n",
    "... how could we predict what users would rate movies they have yet to see?  Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "uApZisVIPsZD",
    "outputId": "a623b75c-6bc4-4dd9-f0c6-1d39b12d5586"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4931584' class='' max='4924029' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.15% [4931584/4924029 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "path = untar_data(URLs.ML_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SetkGmE8PsU3",
    "outputId": "31b36fed-344e-4dfa-93f0-9a62b85554ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c1b3a000-7844-4862-8c52-1d63609e0c57\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1b3a000-7844-4862-8c52-1d63609e0c57')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c1b3a000-7844-4862-8c52-1d63609e0c57 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c1b3a000-7844-4862-8c52-1d63609e0c57');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   user  movie  rating  timestamp\n",
       "0   196    242       3  881250949\n",
       "1   186    302       3  891717742\n",
       "2    22    377       1  878887116\n",
       "3   244     51       2  880606923\n",
       "4   166    346       1  886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv(path/\"u.data\", delimiter=\"\\t\", header=None, names=[\"user\", \"movie\", \"rating\", \"timestamp\"])\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZwsYW9FVDAq"
   },
   "source": [
    "How do we numerically represent user `196` and movie `242`?  With latent factors we don't have to know, we can have such a representation learnt using SGD.\n",
    "\n",
    "**How do we set this up?**\n",
    "\n",
    "1. \"... randomly initialized some parameters [which] will be a set of latent factors for each user and movie.\"\n",
    "\n",
    "2. \"... to calculate our predictions [take] the **dot product** of each movie with each user.\n",
    "\n",
    "3. \"... to calculate our loss ... let's pick mean squared error for now, since that is one reasonable way to represent the accuracy of a prediction\"\n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "**dot product** = element-wise multiplication of two vectors summed up.\n",
    "\n",
    ":::\n",
    "\n",
    "With this in place, \"we can optimize our parameters (the latent factors) using stochastic gradient descent, such as to minimize the loss.\"  In a picture, it looks like this ...\n",
    "\n",
    "![](https://raw.githubusercontent.com/fastai/fastbook/035016fb0cc826542aef77864f36df88a5055d06/images/att_00041.png)\n",
    "\n",
    ":::{.callout-important}\n",
    "\n",
    "The parameters we want to optimize ***are*** the latent factors!\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6EspmYSYXY_t",
    "outputId": "9f1c3b53-f3c0-4aa1-8642-595c66806f65"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6bf302d2-df33-49bd-8119-d9f80286a1e0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bf302d2-df33-49bd-8119-d9f80286a1e0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6bf302d2-df33-49bd-8119-d9f80286a1e0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6bf302d2-df33-49bd-8119-d9f80286a1e0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   movie              title\n",
       "0      1   Toy Story (1995)\n",
       "1      2   GoldenEye (1995)\n",
       "2      3  Four Rooms (1995)\n",
       "3      4  Get Shorty (1995)\n",
       "4      5     Copycat (1995)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv(path/\"u.item\", delimiter=\"|\", header=None, names=[\"movie\", \"title\"], usecols=(0,1), encoding=\"latin-1\")\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "wyriP29rXY9b",
    "outputId": "9276de48-07c6-482c-8a48-b5cf5f9c09b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c2acc2e3-0500-49b3-8024-c4862062b253\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>875747190</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>883888671</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>879138235</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>876503793</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2acc2e3-0500-49b3-8024-c4862062b253')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c2acc2e3-0500-49b3-8024-c4862062b253 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c2acc2e3-0500-49b3-8024-c4862062b253');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   user  movie  rating  timestamp         title\n",
       "0   196    242       3  881250949  Kolya (1996)\n",
       "1    63    242       3  875747190  Kolya (1996)\n",
       "2   226    242       5  883888671  Kolya (1996)\n",
       "3   154    242       3  879138235  Kolya (1996)\n",
       "4   306    242       5  876503793  Kolya (1996)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = ratings_df.merge(movies_df)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "2o17Vvl1XY6y",
    "outputId": "6f048f20-1d89-4ae6-ecf8-ccf5920d42f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>647</td>\n",
       "      <td>Men in Black (1997)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>823</td>\n",
       "      <td>Twelve Monkeys (1995)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>Twelve Monkeys (1995)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>278</td>\n",
       "      <td>In &amp; Out (1997)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>234</td>\n",
       "      <td>Pinocchio (1940)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>823</td>\n",
       "      <td>Phenomenon (1996)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>268</td>\n",
       "      <td>Nell (1994)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>293</td>\n",
       "      <td>Mrs. Doubtfire (1993)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>699</td>\n",
       "      <td>Rock, The (1996)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>405</td>\n",
       "      <td>Best of the Best 3: No Turning Back (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = CollabDataLoaders.from_df(ratings_df, item_name=\"title\", user_name=\"user\", rating_name=\"rating\")\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zVZbmRpcATH"
   },
   "source": [
    "**So how do we create these latent factors for our users and movies?**\n",
    "\n",
    "\"We can represent our movie and user latent factor tables as simple matrices\" that we can index into. But as looking up in an index is not something our models know how to do, we need to use a special PyTorch layer that will do this for us (and more efficiently than using a one-hot-encoded, OHE, vector to do the same). \n",
    "\n",
    "And that layer is called an **embedding**. It \"indexes into a vector using an integer, but has its derivative calcuated in such a way that it is identical to what it would have been if it had done a matric multiplication with a one-hot-encoded vector.\"\n",
    "\n",
    ":::{.callout-important}\n",
    "\n",
    "An embedding is the \"thing that you multiply the one-hot-encoded matrix by (or, using the computational shortcut, inex into directly)\"\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gD20P8-eX1G"
   },
   "source": [
    "## Collaborative Filtering: From Scratch (dot product)\n",
    "\n",
    "A **dot product** approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XR2nMPDPfWVm",
    "outputId": "937db369-6bd7-4d0d-8627-db77619f72b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 1665 5\n"
     ]
    }
   ],
   "source": [
    "n_users = len(dls.classes[\"user\"])\n",
    "n_movies = len(dls.classes[\"title\"])\n",
    "n_factors = 5\n",
    "\n",
    "print(n_users, n_movies, n_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Oqny9aAmeW-2"
   },
   "outputs": [],
   "source": [
    "class DotProduct(Module):\n",
    "  def __init__(self, n_users, n_movies, n_factors):\n",
    "      super().__init__()\n",
    "      self.users_emb = Embedding(n_users, n_factors)\n",
    "      self.movies_emb = Embedding(n_movies, n_factors)\n",
    "\n",
    "  def forward(self, inp):\n",
    "    users = self.users_emb(inp[:,0])\n",
    "    movies = self.movies_emb(inp[:,1])\n",
    "    return (users * movies).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "eVwSz4OkXY4W",
    "outputId": "7653f554-3edc-484c-f06e-ed508e3c6506"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.443892</td>\n",
       "      <td>3.739447</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.088801</td>\n",
       "      <td>1.125219</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.960021</td>\n",
       "      <td>0.994215</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.917181</td>\n",
       "      <td>0.959309</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.903602</td>\n",
       "      <td>0.957268</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProduct(n_users=n_users, n_movies=n_movies, n_factors=n_factors)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqBP8IK5gBWd"
   },
   "source": [
    "### Tip 1: Constrain your range of predictions using `sigmoid_range`\n",
    "\n",
    "\"... to make this model a little bit better ... force those predictions to be between 0 and 5. **One thing we discovered empirically is that it's better to have the range go a little bit over 5**, so we use (0, 5.5)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2KimhjvdXY2K"
   },
   "outputs": [],
   "source": [
    "class DotProduct(Module):\n",
    "  def __init__(self, n_users, n_movies, n_factors, y_range=(0, 5.5)):\n",
    "      super().__init__()\n",
    "      self.users_emb = Embedding(n_users, n_factors)\n",
    "      self.movies_emb = Embedding(n_movies, n_factors)\n",
    "      self.y_range = y_range\n",
    "\n",
    "  def forward(self, inp):\n",
    "    users = self.users_emb(inp[:,0])\n",
    "    movies = self.movies_emb(inp[:,1])\n",
    "    return sigmoid_range((users * movies).sum(dim=1), *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Z9WI6IAtgrJb",
    "outputId": "ea8ca27d-545e-48bd-906c-a2cf3988f9dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.012296</td>\n",
       "      <td>0.994128</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.855805</td>\n",
       "      <td>0.903300</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.707656</td>\n",
       "      <td>0.875159</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482094</td>\n",
       "      <td>0.879115</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.369521</td>\n",
       "      <td>0.884585</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProduct(n_users=n_users, n_movies=n_movies, n_factors=50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACtkqzbZg1Ji"
   },
   "source": [
    "### Tip 2: Add a \"bias\"\n",
    "\n",
    ":::{.callout-important}\n",
    "\n",
    "A **bias** allows your model to learn an overall representation of a thing, rather than just a bunch of characteristics.\n",
    "\n",
    ":::\n",
    "\n",
    "\"One obvious missing piece is that some users are just more positive or negative in their recommendations than others, and some movies are just plain better or worse than others. But in our dot product representation, we do not have any way to encode either of these things ... **because at this point we have only weights; we don't have biases\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gGnx-QIGgrHU"
   },
   "outputs": [],
   "source": [
    "class DotProduct(Module):\n",
    "  def __init__(self, n_users, n_movies, n_factors, y_range=(0, 5.5)):\n",
    "      super().__init__()\n",
    "      self.users_emb = Embedding(n_users, n_factors)\n",
    "      self.users_bias = Embedding(n_users, 1)\n",
    "\n",
    "      self.movies_emb = Embedding(n_movies, n_factors)\n",
    "      self.movies_bias = Embedding(n_movies, 1)\n",
    "\n",
    "      self.y_range = y_range\n",
    "\n",
    "  def forward(self, inp):\n",
    "    # embeddings\n",
    "    users = self.users_emb(inp[:,0])\n",
    "    movies = self.movies_emb(inp[:,1])\n",
    "\n",
    "    # calc our dot product and add in biases \n",
    "    # (important to include \"keepdim=True\" => res.shape = (64,1), else will get rid of dims equal to 1 and you just get (64))\n",
    "    res = (users * movies).sum(dim=1, keepdim=True)\n",
    "    res += self.users_bias(inp[:,0]) + self.movies_bias(inp[:,1])\n",
    "\n",
    "    # return our target constrained prediction\n",
    "    return sigmoid_range(res, *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tZ9Nws5hgrE3",
    "outputId": "15b23a24-1404-4788-c7a0-0488ec51fa9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.925160</td>\n",
       "      <td>0.938387</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.807021</td>\n",
       "      <td>0.863466</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.607999</td>\n",
       "      <td>0.871146</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.412089</td>\n",
       "      <td>0.897263</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294376</td>\n",
       "      <td>0.905192</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProduct(n_users=n_users, n_movies=n_movies, n_factors=50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucJEXJlVjNRn"
   },
   "source": [
    "### Tip 3: Add \"weight decay\"\n",
    "\n",
    "Adding in bias has made are model more complex and therefore more prone to overfitting (which seems to be happening here).\n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "**Overfitting** is where your validation stops improving and actually starts to get worse.\n",
    "\n",
    ":::\n",
    "\n",
    "**What do you do when your model overfits?**\n",
    "\n",
    "We can solve this via data augmentation or by including one or more forms of **regularization** (e.g., a means to \"encourage the weights to be as small as possible\".\n",
    "\n",
    "**What is \"weight decay\" (aka \"L2 regularization\")?**\n",
    "\n",
    "\"... consists of adding to your loss function the sum of all the weights squared.\"\n",
    "\n",
    "**Why do that?**\n",
    "\n",
    "\"Because when we compute the gradients, it will add a contribution to them that will encourage the weights to be as small as possible.\"\n",
    "\n",
    "**Why would this prevent overfitting?**\n",
    "\n",
    "\"The idea is that the larger the coefficients are, the sharper canyons we will have in the loss function.... **Letting our model learn high parameters might cause it to fit all the data points in the training set with an overcomplex function that has very sharp changes, which will lead to overfitting**.\n",
    "\n",
    ":::{.callout-important}\n",
    "\n",
    "\"Limiting our weights from growing too much is going to hinder the training of the model ***but*** it will yield a state where it generalizes better\"\n",
    "\n",
    ":::\n",
    "\n",
    "**How do we add weight decay into are training?**\n",
    "\n",
    "\"... `wd` is a parameter that **controls that sum of squares we add to our loss\" as such:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "u-xyKczYgrCb",
    "outputId": "f59928fa-8df1-4991-98ff-49a61e96a2db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.934345</td>\n",
       "      <td>0.946092</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.866700</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.715633</td>\n",
       "      <td>0.829172</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.597503</td>\n",
       "      <td>0.817248</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.473108</td>\n",
       "      <td>0.817725</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProduct(n_users=n_users, n_movies=n_movies, n_factors=50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JRnnJRFmTww"
   },
   "source": [
    "### Creating our own Embedding Module\n",
    "\n",
    "pp.265-267 show how to write your own `nn.Module` that does what `Embedding` does.  Here are some of the important bits to pay attention too ...\n",
    "\n",
    "\"... optimizers require that they can get all the parameters of a module from the module's `parameters` method, so make sure to tell `nn.Module` that you want to treat a tensor as a parameters using the `nn.Parameter` class like so:\n",
    "\n",
    "```python\n",
    "class T(Module):\n",
    "  def __init__(self):\n",
    "    self.a = nn.Parameter(torch.ones(3))\n",
    "```\n",
    "\n",
    ":::{.callout-important}\n",
    "\n",
    "\"All PyTorch modules use `nn.Parameter` for any trainable parameters.\n",
    "\n",
    ":::\n",
    "\n",
    "```python\n",
    "class T(Module):\n",
    "  def __init__(self):\n",
    "    self.a = nn.Liner(1, 3, bias=False)\n",
    "\n",
    "t = T()\n",
    "t.parameters()   #=> will show all the weights of your nn.Linear\n",
    "type(t.a.weight) #=> torch.nn.parameter.Parameter\n",
    "```\n",
    "\n",
    "Now, given a method like this ...\n",
    "\n",
    "```python\n",
    "def create_params(size):\n",
    "  return nn.Parameter(torch.zeros(*size).normal_(0, 0.01))\n",
    "```\n",
    "\n",
    "... we can create randomly initialized parameters, included parameters for our latent factors and biases like this:\n",
    "\n",
    "```python\n",
    "self.users_emb = create_params([n_users, n_factors])\n",
    "self.users_bias = create_params([n_users])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Gh6l7n-oZNF"
   },
   "source": [
    "## Interpreting Embeddings and Biases\n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "\"... interesting to see what parameters it has discovered ... easiest to interpret are the biases\"\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zntW403SoaT6",
    "outputId": "53fd4723-3c65-497c-8695-d3b6d93bdf33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children of the Corn: The Gathering (1996)',\n",
       " 'Big Bully (1996)',\n",
       " 'Showgirls (1995)',\n",
       " 'Lawnmower Man 2: Beyond Cyberspace (1996)',\n",
       " 'Free Willy 3: The Rescue (1997)']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_bias = learn.model.movies_bias.weight.squeeze() # => squeeze will get rid of all the single dimensions\n",
    "idxs = movie_bias.argsort()[:5]                       # => \"argsort()\" returns the indices sorted by value\n",
    "[dls.classes[\"title\"][i] for i in idxs]               # => look up the movie title in dls.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf2xLgsEQMTD"
   },
   "source": [
    "\"Think about what this means .... It tells us not just whether a movie is of a kind that people tend not to enjoy watching, but that people tend to not like watching it even if it is of a kind that they would otherwise enjoy!\"\n",
    "\n",
    "To get the movies by highest bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CoKcZZL5oaP6",
    "outputId": "fbc198bd-cbd6-4835-a631-386661c1c2bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Titanic (1997)',\n",
       " \"Schindler's List (1993)\",\n",
       " 'As Good As It Gets (1997)',\n",
       " 'L.A. Confidential (1997)',\n",
       " 'Shawshank Redemption, The (1994)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = movie_bias.argsort(descending=True)[:5]\n",
    "[dls.classes[\"title\"][i] for i in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aquKE2rQRQ6W"
   },
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "To visualize embeddings with many factors, you \"can pull out the most important underlying directions\" using a dimensionality reduction model like **principal components analysis** (PCA).\n",
    "\n",
    ":::\n",
    "\n",
    "See p.268 and these three StatQuest videos for more on how PCA works (btw, StatQuest is one of my top data science references so consider subscribing to his channel). [Video 1](https://www.youtube.com/watch?v=HMOI_lkzW08&t=13s), [Video 2](https://www.youtube.com/watch?v=FgakZw6K1QQ), and [Video 3](https://www.youtube.com/watch?v=oRvgq966yZg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN6zIYiiSbJC"
   },
   "source": [
    "## Collaborative Filtering: Using `fastai.collab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dHySGhkMoaMD",
    "outputId": "ad3802a4-1ebd-4e6f-e782-fc03371cf3dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.950606</td>\n",
       "      <td>0.930099</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.834664</td>\n",
       "      <td>0.870282</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.723968</td>\n",
       "      <td>0.833274</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.573679</td>\n",
       "      <td>0.819824</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.489258</td>\n",
       "      <td>0.820394</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8A9Thc53oaIg",
    "outputId": "a1f0b69e-a702-4a17-845b-ce8c42511ccc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingDotBias(\n",
       "  (u_weight): Embedding(944, 50)\n",
       "  (i_weight): Embedding(1665, 50)\n",
       "  (u_bias): Embedding(944, 1)\n",
       "  (i_bias): Embedding(1665, 1)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELO_LAgloZrU",
    "outputId": "3dbd8c91-358a-4016-a869-9eda35a10e3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children of the Corn: The Gathering (1996)',\n",
       " 'Showgirls (1995)',\n",
       " 'Barb Wire (1996)',\n",
       " 'Island of Dr. Moreau, The (1996)',\n",
       " 'Cable Guy, The (1996)']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_bias = learn.model.i_bias.weight.squeeze() \n",
    "idxs = movie_bias.argsort()[:5]                   \n",
    "[dls.classes[\"title\"][i] for i in idxs]              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HULEAvrTFmC"
   },
   "source": [
    "## Embedding Distance\n",
    "\n",
    "\"Another thing we can do with these learned embeddings is to look at distance.\"\n",
    "\n",
    "**Why do this?**\n",
    "\n",
    "\"If there were two movies that were nearly identical, their embedding vectors would also have to be nearly identical .... There is a more general idea here: movie similairty can be defined by the similarity of users who like those movies. And that directly means that the distance between two movies' embedding vectors can define that similarity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "18g8ArWNTFV-",
    "outputId": "2661298b-57cc-4196-94ba-037115d57a3a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Dial M for Murder (1954)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_factors = learn.model.i_weight.weight\n",
    "idx = dls.classes[\"title\"].o2i[\"Silence of the Lambs, The (1991)\"]\n",
    "dists = nn.CosineSimilarity(dim=1)(movie_factors, movie_factors[idx][None])\n",
    "targ_idx = dists.argsort(descending=True)[1]\n",
    "dls.classes[\"title\"][targ_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrOldbnNUr-A"
   },
   "source": [
    "## Bootstrapping\n",
    "\n",
    "The **bootstrapping problem** asks how we can make recommendations when we have a new user for which no data exists or a new product/movie for which no reviews have been made?\n",
    "\n",
    "The recommended approach \"is to **use a tabular model based on user metadata to construct your initial embedding vector.** When a new user signs up, think about what questions you could ask to help you understand their tastes. Then you can create a model in which **the dependent variable is a user's embedding vector**, and **the independent variables are the results of the questions that you ask them, along with their signup metadata**.\"\n",
    "\n",
    ":::{.callout-important}\n",
    "\n",
    "Be aware of the \"problem of **representation bias**\" (e.g., where a few very active users end up skewing the results).\n",
    "\n",
    ":::\n",
    "\n",
    "See p.271 for more information on how collaborative models may contribute to positive feedback loops and how humans can mitigate by being part of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7KrxRbNQN4A"
   },
   "source": [
    "## Collaborative Filtering: From Scratch (NN)\n",
    "\n",
    "A **neural network** approach requires we \"take the results of the embedding lookup and concatenate those activations together. This gives us a matrix we can then pass through linear layers and nonlinearities...\"\n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "Because \"we'll be concatenating the embedding matrices, rather than taking their dot product, **the two embedding matrices can have different sizes (different numbers of latent factors)**\"\n",
    "\n",
    ":::\n",
    "\n",
    "**How do we determine the number of latent factors a \"thing\" should have?**\n",
    "\n",
    "Use `get_emb_sz` to return \"the recommended sizes for embedding matrices for your data, **based on a heuristic that fast.ai has found tends to work well in practice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joRNY3TmTFSp",
    "outputId": "91767a50-ee06-401a-f137-59511a3f9aaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(944, 74), (1665, 102)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = get_emb_sz(dls)\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "tQglpC9xTFPc"
   },
   "outputs": [],
   "source": [
    "class CollabNN(Module):\n",
    "  def __init__(self, user_sz, item_sz, y_range=(0, 0.5), n_act=100):\n",
    "    self.user_factors = Embedding(*user_sz)\n",
    "    self.item_factors = Embedding(*item_sz)\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(user_sz[1] + item_sz[1], n_act),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(n_act, 1)\n",
    "    )\n",
    "    self.y_range = y_range\n",
    "\n",
    "  def forward(self, x):\n",
    "    embs = self.user_factors(x[:,0]), self.item_factors(x[:,1])\n",
    "    x = self.layers(torch.cat(embs, dim=1))\n",
    "    return sigmoid_range(x, *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Rpt4qs8GTFMH",
    "outputId": "21ff26d5-8b5a-4c64-fb8f-b34ed6e0c8d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.594646</td>\n",
       "      <td>10.379806</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.368298</td>\n",
       "      <td>10.379800</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10.565783</td>\n",
       "      <td>10.379800</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.439667</td>\n",
       "      <td>10.379800</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.356900</td>\n",
       "      <td>10.379800</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CollabNN(*embs)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSe_dtJYUvNL"
   },
   "source": [
    "If we use the `collab_learner`, will will calculate our embedding sizes for us and also give us the option of defining how many more layers we want to tack on via the `layers` parameter.  All we have to do is tell it to `use_nn=True` to use a NN rather than the default dot-product model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "I8TTO2xvTFBk"
   },
   "outputs": [],
   "source": [
    "learn = collab_learner(dls, use_nn=True, y_range=(0,0.5), layers=[100,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1xLPa_niTU2Y",
    "outputId": "ec5fa2fe-bb33-486d-a81c-ca1920f034db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingNN(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(944, 74)\n",
       "    (1): Embedding(1665, 102)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.0, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): Linear(in_features=176, out_features=100, bias=False)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): Linear(in_features=100, out_features=50, bias=False)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): LinBnDrop(\n",
       "      (0): Linear(in_features=50, out_features=1, bias=True)\n",
       "    )\n",
       "    (3): SigmoidRange(low=0, high=0.5)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8H7c7QVOTXSe",
    "outputId": "b03e1805-c8b7-4080-ae11-edce84b9d874"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.274985</td>\n",
       "      <td>10.379872</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.555515</td>\n",
       "      <td>10.379800</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10.436097</td>\n",
       "      <td>10.379800</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.481320</td>\n",
       "      <td>10.379800</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.400410</td>\n",
       "      <td>10.379800</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EFWgtUyVUFw"
   },
   "source": [
    "**Why use a neural network (NN)?**\n",
    "\n",
    "Because \"we can now directly incorporate other user and movie information, date and time information, or any other information that may be relevant to the recommendation.\"\n",
    "\n",
    "We'll see this when we look at `TabularModel` (of which `EmbeddingNN` is a subclass with no continuous data [`n_cont=0`] and an `out_sz=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_aJzslyV1aQ"
   },
   "source": [
    "## `kwargs` and `@delegates`\n",
    "\n",
    "Some helpful notes for both are included on pp.273-274.  In short ...\n",
    "\n",
    "`**kwargs`:\n",
    "\n",
    "1. `**kwargs` as a **parameter** = \"put any additional keyword arguments into a dict called `kwargs`\"\n",
    "2. `**kwargs` passed as an **argument** = \"insert all key/value pairs in the `kwargs` dict as named arguments here.\"\n",
    "\n",
    "`@delegates`:\n",
    " \n",
    " \"... fastai resolves [the issue of using `**kwargs` to avoid having to write out all the arguments of the base class] by providing a special `@delegates` decorator, which automatically **changes the signature of the class or function** ... to insert all of its keyword arguments into the signature.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSwEOzDpHHBj"
   },
   "source": [
    "## Resources\n",
    "\n",
    "1. https://book.fast.ai - The book's website; it's updated regularly with new content and recommendations from everything to GPUs to use, how to run things locally and on the cloud, etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "B2wEfmj5CLA8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2022-03-31-ajtfb-chapter-8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ohmeow_website')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9eb9bda8f49c57e6addc88daf9eb4f6c227a77e767b644e5d20488a497d532a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
